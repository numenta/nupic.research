# ----------------------------------------------------------------------
# Numenta Platform for Intelligent Computing (NuPIC)
# Copyright (C) 2020, Numenta, Inc.  Unless you have an agreement
# with Numenta, Inc., for a separate license for this software code, the
# following terms and conditions apply:
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero Public License version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero Public License for more details.
#
# You should have received a copy of the GNU Affero Public License
# along with this program.  If not, see http://www.gnu.org/licenses.
#
# http://numenta.org/licenses/
# ----------------------------------------------------------------------

import abc
import logging
import time
from pprint import pformat

from nupic.research.frameworks.pytorch.model_utils import set_random_seed

__all__ = [
    "BaseExperiment",
]


class BaseExperiment(abc.ABC):
    """
    This class provides an interface for pytorch experiments. Subclasses define
    what should happen during setup, what should happen on each iteration of the
    experiment, and when the experiment should stop. The API is designed for
    extensibility via object-oriented-programming and/or mixins.

    Callers will implement the loop:

        exp = ExperimentClass()
        exp.setup_experiment(config)

        first_run = True
        while not exp.should_stop():
            if first_run:
                pre_result = exp.run_pre_experiment()
                print(pre_result)
            result = exp.run_iteration()
            if first_run:
                ExperimentClass.insert_pre_experiment_result(result, pre_result)
                first_run = False
            print(ExperimentClass.get_printable_result(result))
            save_iteration_somehow(result)  # Example-specific logging
    """
    def setup_experiment(self, config):
        """
        Configure the experiment for training

        :param config: Dictionary containing the configuration parameters

            - local_dir: Results path
            - logdir: Directory generated by Ray Tune for this Trial
            - log_timestep_freq: Configures mixins and subclasses that log every
                                 timestep to only log every nth timestep (in
                                 addition to the final timestep of each epoch).
                                 Set to 0 to log only at the end of each epoch.
            - progress: Show progress during training
            - name: Experiment name. Used as logger name
            - log_level: Python Logging level
            - log_format: Python Logging format
            - seed: the seed to be used for pytorch, python, and numpy
            - checkpoint_at_init: boolean argument for whether to create a checkpoint
                                  of the initialized model. this differs from
                                  `checkpoint_at_start` for which the checkpoint occurs
                                  after the first epoch of training as opposed to
                                  before it
            - launch_time: time the config was created (via time.time). Used to report
                           wall clock time until the first batch is done.
                           Default: time.time() in this setup_experiment().
        """
        # Configure logging related stuff
        log_format = config.get("log_format", logging.BASIC_FORMAT)
        log_level = getattr(logging, config.get("log_level", "INFO").upper())
        console = logging.StreamHandler()
        console.setFormatter(logging.Formatter(log_format))
        self.logger = logging.getLogger(config.get("name", type(self).__name__))
        self.logger.setLevel(log_level)
        self.logger.addHandler(console)
        self.progress = config.get("progress", False)
        self.launch_time = config.get("launch_time", time.time())
        self.logdir = config.get("logdir", None)

        if config.get("disable_logger", False):
            self.logger.disabled = True
            self.progress = False

        # Configure seed
        self.seed = config.get("seed", 42)
        set_random_seed(self.seed, False)

        self.logger.info("Execution order: %s",
                         pformat(self.get_execution_order()))

    @abc.abstractmethod
    def run_iteration(self):
        """
        Run one training iteration of the experiment and return some sort of
        result.
        """

    @abc.abstractmethod
    def should_stop(self):
        """
        Whether or not the experiment should stop. Usually determined by the
        number of epochs but customizable to any other stopping criteria
        """

    def stop_experiment(self):
        """
        Perform any needed cleanup.
        """

    def run_pre_experiment(self):
        """
        Evaluate the model before performing any training and return some sort
        of result. If the experiment is configured to skip the pre_experiment,
        return None.
        """
        return None

    @classmethod
    def insert_pre_experiment_result(cls, result, pre_experiment_result):
        """
        Modify result to incorporate the pre_experiment_result. By default, this
        method performs no update. (This may be sufficient, for example if the
        pre_experiment_result has already been printed to the console.)

        :param pre_experiment_results: The return value of pre_experiment
        """

    def get_state(self):
        """
        Get experiment serialized state as a dictionary of  byte arrays
        :return: dictionary with "model", "optimizer" and "lr_scheduler" states
        """
        return {}

    def set_state(self, state):
        """
        Restore the experiment from the state returned by `get_state`
        :param state: dictionary with "model", "optimizer", "lr_scheduler"
        states
        """

    @classmethod
    def get_printable_result(cls, result):
        """
        Return a stripped down version of result that has its large data structures
        removed so that the result can be printed to the console.
        """
        return result

    @classmethod
    def get_execution_order(cls):
        """
        Gets a dict that can be printed to show the order of events that occur
        for each method. Subclasses and mixins should extend this method,
        modifying each list of events according to when/whether they call
        super().
        """
        exp = "BaseExperiment"
        return dict(
            setup_experiment=[exp + ".setup_experiment"],
            create_optimizer=[exp + ".create_optimizer"],
            run_iteration=[],
            run_pre_experiment=[exp + ": No pre_experiment implemented"],
            get_printable_result=[exp + ": Return unfiltered result"],
            stop_experiment=[],
            get_state=[],
            set_state=[],
        )
