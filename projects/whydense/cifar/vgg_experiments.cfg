# ----------------------------------------------------------------------
# Numenta Platform for Intelligent Computing (NuPIC)
# Copyright (C) 2019, Numenta, Inc.  Unless you have an agreement
# with Numenta, Inc., for a separate license for this software code, the
# following terms and conditions apply:
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero Public License version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero Public License for more details.
#
# You should have received a copy of the GNU Affero Public License
# along with this program.  If not, see http://www.gnu.org/licenses.
#
# http://numenta.org/licenses/
# ----------------------------------------------------------------------

[DEFAULT]
path = results

# Set to 'True' to save/restore the model on every iteration and repetition
restore_supported = True

experiment = grid

# Training
weight_decay = 0.0005

# Common network parameters
input_shape = (3, 32, 32)
boost_strength = 1.5
boost_strength_factor = 0.85
k_inference_factor = 1.5

# Three layer specific parameters:
iterations = 200
repetitions = 5
batch_size = 64
batches_in_epoch = 250
first_epoch_batch_size = 4
batches_in_first_epoch = 600
test_batch_size = 128
test_batches_in_epoch = 500
learning_rate = 0.1
momentum = 0.5
learning_rate_gamma = 0.97

network_type = vgg
block_sizes = [1, 1, 1]
cnn_percent_on = [0.1, 0.1, 1.0]
cnn_weight_sparsity = [1.0, 0.5, 1.0]
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = [10, 12, 14]
linear_n = [50, 60]
linear_percent_on = [0.2, 1.0]
weight_sparsity = [0.3, 1.0]

stop = {"stop": 1}
checkpoint_at_end = True


[quick]
iterations = 3
repetitions = 1
batch_size = 4
batches_in_epoch = 4
first_epoch_batch_size = 4
batches_in_first_epoch = 4
test_batch_size = 4
test_batches_in_epoch = 4
block_sizes = [2, 3, 1]


[decentSparse]
iterations = 100
repetitions = 1
block_sizes = [1,3,2]
cnn_percent_on = [0.25, 0.25, 0.25]
cnn_weight_sparsity = [1.0, 0.5, 0.8]
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = [64, 128, 192]
linear_n = [550]
linear_percent_on = [1.0]
weight_sparsity = [1.0]
model_filename = "decentSparse.pth"


[decent2Linear]
iterations = 100
repetitions = 1
cnn_weight_sparsity = [ 0.45, 0.88, 0.74 ]
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = [ 125, 93, 103 ]
linear_n = [578, 500]
linear_percent_on = [0.3, 0.3]
weight_sparsity = [0.5, 0.5]


[blockSizes]
iterations = 200
repetitions = 6
block_sizes = tune.sample_from(lambda spec: [np.random.randint(1,3), np.random.randint(1,3), np.random.randint(1,3)])
cnn_weight_sparsity = [ 0.2, 0.2, 0.2 ]
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = [ 64, 128, 128 ]
linear_n = [550]
linear_percent_on = [0.2]
weight_sparsity = [0.3]


[layerSearchSparse]
iterations = 125
repetitions = 20
block_sizes = tune.sample_from(lambda spec: [np.random.randint(1,3), np.random.randint(1,4), np.random.randint(1,4)])
cnn_percent_on = tune.sample_from(lambda spec: [np.random.randint(5,30)/100.0, np.random.randint(5,30)/100.0, np.random.randint(5,30)/100.0])
cnn_weight_sparsity = tune.sample_from(lambda spec: [np.random.randint(30,100)/100.0, np.random.randint(30,100)/100.0, np.random.randint(30,100)/100.0])
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = tune.sample_from(lambda spec: [np.random.randint(32,128), np.random.randint(32,128), np.random.randint(32,196)])
linear_n = [550]
linear_percent_on = [0.3]
weight_sparsity = [0.4]


[layerSearchDense]
iterations = 100
repetitions = 6
block_sizes = tune.sample_from(lambda spec: [np.random.randint(1,4), np.random.randint(1,4), np.random.randint(1,4)])
cnn_percent_on = [1.0, 1.0, 1.0]
cnn_weight_sparsity = [1.0, 1.0, 1.0]
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = tune.sample_from(lambda spec: [np.random.randint(32,128), np.random.randint(32,128), np.random.randint(32,128)])
linear_n = [550]
linear_percent_on = [1.0]
weight_sparsity = [1.0]

# Don't stop early
stop = {}


# Focus a bit more on the linear layer
[layerSearchSparse2]
iterations = 125
repetitions = 40
block_sizes = tune.sample_from(lambda spec: [1, np.random.randint(1,4), np.random.randint(1,4)])
cnn_percent_on = tune.sample_from(lambda spec: [np.random.randint(20,30)/100.0, np.random.randint(20,30)/100.0, np.random.randint(20,30)/100.0])
cnn_weight_sparsity = tune.sample_from(lambda spec: [1.0, np.random.randint(50,100)/100.0, np.random.randint(50,100)/100.0])
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = tune.sample_from(lambda spec: [np.random.randint(50,128), np.random.randint(50,128), np.random.randint(50,196)])
linear_n = tune.sample_from(lambda spec: [np.random.randint(300,800), np.random.randint(300,800)])
linear_percent_on = [0.3, 0.3]
weight_sparsity = [0.4, 0.4]


# Focus a bit more on boost factors
[layerSearchSparse3]
iterations = 125
repetitions = 40
boost_strength_factor = tune.sample_from(lambda spec: np.random.randint(1,20)/100.0 + 0.8)
block_sizes = [1,3,2]
cnn_percent_on = tune.sample_from(lambda spec: [np.random.randint(20,30)/100.0, np.random.randint(20,30)/100.0, np.random.randint(20,30)/100.0])
cnn_weight_sparsity = tune.sample_from(lambda spec: [1.0, np.random.randint(50,100)/100.0, np.random.randint(50,100)/100.0])
cnn_kernel_size = [5, 5, 3]
cnn_out_channels = tune.sample_from(lambda spec: [np.random.randint(50,128), np.random.randint(50,128), np.random.randint(50,196)])
linear_n = [550]
linear_percent_on = [1.0]
weight_sparsity = [1.0]

