[DEFAULT]
# Uncomment to upload results on S3
;upload_dir = "s3://bucketname/ray"
;sync_function = "aws s3 sync `dirname {local_dir}` {remote_dir}/`basename $(dirname {local_dir})`"

path = results
seed = 18
verbose = 0
data_dir="data"
checkpoint_freq = 0
checkpoint_at_end = True

iterations=1
batch_size=64
batches_in_epoch=100000
test_batch_size=100000

loss_function = "nn.functional.cross_entropy"
learning_scheduler_gamma=0.1
learning_scheduler_step_size=1
learning_rate=0.1
weight_decay=0.0001
momentum=0.9
nesterov = False

data_augmentation = True
num_classes=10
growth_rate=12
bottleneck_size=4
avg_pool_size=8
reduction=0.5

dense_percent_on=([1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0])
transition_percent_on=(1.0, 1.0, 1.0)
classifier_percent_on=1.0
k_inference_factor=1.0
boost_strength=1.5
boost_strength_factor=0.95
duty_cycle_period=1000

[DenseNet_depth100_k12]
verbose = 2
depth=100
growth_rate=12
bottleneck_size=4
avg_pool_size=8
batch_size=64
iterations=100
learning_scheduler_milestones=50,75
learning_scheduler_gamma=0.1
learning_rate=0.1
weight_decay=0.0001
nesterov=True
momentum=0.9

[DenseNet18]
learning_rate = 0.05
iterations = 50
learning_scheduler_gamma = 0.92
block_config = (2, 4, 8, 4)
weight_decay = 0.0005
avg_pool_size = 2
growth_rate = 72
momentum = 0.9

[NotSoDenseNet18]
learning_rate = 0.05
iterations = 50
learning_scheduler_gamma = 0.92
block_config = (2, 4, 8, 4)
transition_percent_on = (0.2, 0.2, 0.4)
weight_decay = 0.0005
avg_pool_size = 2
growth_rate = 72
momentum = 0.9
classifier_percent_on = 0.2
;linear_n = 400
;dense_c1_out_planes = 144
;linear_sparsity = 0.2
;restore_supported = False
;experiment = grid
;conv1_sparsity = 0.2
;linear_weight_sparsity = 0.3
