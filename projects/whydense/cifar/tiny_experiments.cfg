# ----------------------------------------------------------------------
# Numenta Platform for Intelligent Computing (NuPIC)
# Copyright (C) 2019, Numenta, Inc.  Unless you have an agreement
# with Numenta, Inc., for a separate license for this software code, the
# following terms and conditions apply:
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero Public License version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero Public License for more details.
#
# You should have received a copy of the GNU Affero Public License
# along with this program.  If not, see http://www.gnu.org/licenses.
#
# http://numenta.org/licenses/
# ----------------------------------------------------------------------

[DEFAULT]
path = results
seed = 42

# Set to 'True' to save/restore the model on every iteration and repetition
restore_supported = True

experiment = grid
repetitions = 1

# Training
iterations = 60
weight_decay = 0.0005

# Common network parameters
input_shape = (3, 32, 32)
out_channels = 32

boost_strength = 1.5
boost_strength_factor = 0.85
k_inference_factor = 1.5

[quick]
iterations = 3
batch_size = 4
batches_in_epoch = 2
first_epoch_batch_size = 4
batches_in_first_epoch = 2
test_batch_size = 4
test_batches_in_epoch = 2
learning_rate = 0.05
momentum = 0.9
lr_scheduler_gamma = 0.9

network_type = tiny_sparse
cnn_k = [0.1, 0.1]
out_channels = [8, 8]
linear_n = 100
linear_k = 0.1
weight_sparsity = 0.3

;# No sparse weights for first conv layer.
[tinySparse]
iterations = 10
batch_size = 32
batches_in_epoch = 500
first_epoch_batch_size = 4
batches_in_first_epoch = 600
test_batch_size = 32
test_batches_in_epoch = 500
learning_rate = 0.01
momentum = 0.9
lr_scheduler_gamma = 0.9

network_type = tiny_sparse
cnn_k = [0.2, 0.2]
out_channels = [8, 8]
linear_n = 100
linear_k = 0.2
weight_sparsity = 0.4


[tinyDense]
iterations = 10
batch_size = 32
batches_in_epoch = 500
first_epoch_batch_size = 4
batches_in_first_epoch = 600
test_batch_size = 32
test_batches_in_epoch = 500
learning_rate = 0.01
momentum = 0.9
lr_scheduler_gamma = 0.9

network_type = tiny_sparse
cnn_k = [1.0, 1.0]
out_channels = [8, 8]
linear_n = 100
linear_k = 1.0
weight_sparsity = 1.0
