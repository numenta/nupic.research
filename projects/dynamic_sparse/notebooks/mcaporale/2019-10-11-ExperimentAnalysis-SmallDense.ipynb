{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment: \n",
    "\n",
    "Evaluate pruning by magnitude weighted by coactivations (more thorough evaluation), compare it to baseline (SET).\n",
    "\n",
    "#### Motivation.\n",
    "\n",
    "Check if results are consistently above baseline.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "- No significant difference between both models\n",
    "- No support for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tabulate\n",
    "import pprint\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray.tune.commands import *\n",
    "from nupic.research.frameworks.dynamic_sparse.common.browser import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsc-smalldense\n"
     ]
    }
   ],
   "source": [
    "base = os.path.join('gsc-smalldense-2019-10-11-exp1')\n",
    "exps = [\n",
    "    os.path.join(base, exp) for exp in [\n",
    "        'gsc-smalldense'\n",
    "    ]\n",
    "]\n",
    "paths = [os.path.expanduser(\"~/nta/results/{}\".format(e)) for e in exps]\n",
    "df = load_many(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment Name</th>\n",
       "      <th>train_acc_max</th>\n",
       "      <th>train_acc_max_epoch</th>\n",
       "      <th>train_acc_min</th>\n",
       "      <th>train_acc_min_epoch</th>\n",
       "      <th>train_acc_median</th>\n",
       "      <th>train_acc_last</th>\n",
       "      <th>val_acc_max</th>\n",
       "      <th>val_acc_max_epoch</th>\n",
       "      <th>val_acc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>lr_gamma</th>\n",
       "      <th>lr_milestones</th>\n",
       "      <th>lr_scheduler</th>\n",
       "      <th>model</th>\n",
       "      <th>momentum</th>\n",
       "      <th>net_params</th>\n",
       "      <th>network</th>\n",
       "      <th>optim_alg</th>\n",
       "      <th>test_noise</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.722293</td>\n",
       "      <td>92</td>\n",
       "      <td>0.256079</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705961</td>\n",
       "      <td>0.714383</td>\n",
       "      <td>0.792712</td>\n",
       "      <td>45</td>\n",
       "      <td>0.286050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.836149</td>\n",
       "      <td>92</td>\n",
       "      <td>0.224685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826238</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>65</td>\n",
       "      <td>0.305643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.874426</td>\n",
       "      <td>65</td>\n",
       "      <td>0.288595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864466</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.936912</td>\n",
       "      <td>78</td>\n",
       "      <td>0.447492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>92</td>\n",
       "      <td>0.300410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880163</td>\n",
       "      <td>0.891710</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>78</td>\n",
       "      <td>0.298197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>96</td>\n",
       "      <td>0.327995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887194</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>55</td>\n",
       "      <td>0.486677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.714481</td>\n",
       "      <td>92</td>\n",
       "      <td>0.169905</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698662</td>\n",
       "      <td>0.707450</td>\n",
       "      <td>0.781740</td>\n",
       "      <td>85</td>\n",
       "      <td>0.137539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.836588</td>\n",
       "      <td>98</td>\n",
       "      <td>0.231081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824187</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>0.907132</td>\n",
       "      <td>98</td>\n",
       "      <td>0.296630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.872913</td>\n",
       "      <td>93</td>\n",
       "      <td>0.251343</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862465</td>\n",
       "      <td>0.869544</td>\n",
       "      <td>0.928292</td>\n",
       "      <td>46</td>\n",
       "      <td>0.378918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.895030</td>\n",
       "      <td>91</td>\n",
       "      <td>0.317547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882873</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>45</td>\n",
       "      <td>0.528997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>96</td>\n",
       "      <td>0.305146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890562</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>32</td>\n",
       "      <td>0.391066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>61</td>\n",
       "      <td>0.174202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522776</td>\n",
       "      <td>0.688849</td>\n",
       "      <td>0.789577</td>\n",
       "      <td>99</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.838688</td>\n",
       "      <td>98</td>\n",
       "      <td>0.252856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827361</td>\n",
       "      <td>0.837076</td>\n",
       "      <td>0.909875</td>\n",
       "      <td>66</td>\n",
       "      <td>0.375784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.873499</td>\n",
       "      <td>80</td>\n",
       "      <td>0.214530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863563</td>\n",
       "      <td>0.868519</td>\n",
       "      <td>0.928292</td>\n",
       "      <td>76</td>\n",
       "      <td>0.126567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.897422</td>\n",
       "      <td>96</td>\n",
       "      <td>0.295821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886437</td>\n",
       "      <td>0.889806</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>92</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.901572</td>\n",
       "      <td>90</td>\n",
       "      <td>0.302217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.890587</td>\n",
       "      <td>0.951019</td>\n",
       "      <td>77</td>\n",
       "      <td>0.505486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.711015</td>\n",
       "      <td>92</td>\n",
       "      <td>0.175471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.707206</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>97</td>\n",
       "      <td>0.157524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.836784</td>\n",
       "      <td>93</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826018</td>\n",
       "      <td>0.829948</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>99</td>\n",
       "      <td>0.321317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.873694</td>\n",
       "      <td>96</td>\n",
       "      <td>0.244751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857802</td>\n",
       "      <td>0.868909</td>\n",
       "      <td>0.929075</td>\n",
       "      <td>63</td>\n",
       "      <td>0.359326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.898399</td>\n",
       "      <td>91</td>\n",
       "      <td>0.236989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886144</td>\n",
       "      <td>0.890440</td>\n",
       "      <td>0.941614</td>\n",
       "      <td>25</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.905869</td>\n",
       "      <td>92</td>\n",
       "      <td>0.266771</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.902402</td>\n",
       "      <td>0.950235</td>\n",
       "      <td>92</td>\n",
       "      <td>0.366379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.717117</td>\n",
       "      <td>98</td>\n",
       "      <td>0.156625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705180</td>\n",
       "      <td>0.709403</td>\n",
       "      <td>0.784875</td>\n",
       "      <td>50</td>\n",
       "      <td>0.152038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.835075</td>\n",
       "      <td>92</td>\n",
       "      <td>0.260668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820940</td>\n",
       "      <td>0.829704</td>\n",
       "      <td>0.911834</td>\n",
       "      <td>73</td>\n",
       "      <td>0.404781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.873303</td>\n",
       "      <td>94</td>\n",
       "      <td>0.263988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863099</td>\n",
       "      <td>0.869007</td>\n",
       "      <td>0.929075</td>\n",
       "      <td>50</td>\n",
       "      <td>0.370298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.893419</td>\n",
       "      <td>96</td>\n",
       "      <td>0.250952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880871</td>\n",
       "      <td>0.889220</td>\n",
       "      <td>0.938871</td>\n",
       "      <td>76</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.903086</td>\n",
       "      <td>98</td>\n",
       "      <td>0.331511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892344</td>\n",
       "      <td>0.901621</td>\n",
       "      <td>0.949843</td>\n",
       "      <td>45</td>\n",
       "      <td>0.429075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.716922</td>\n",
       "      <td>96</td>\n",
       "      <td>0.172542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>0.713505</td>\n",
       "      <td>0.792712</td>\n",
       "      <td>74</td>\n",
       "      <td>0.145376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.834977</td>\n",
       "      <td>93</td>\n",
       "      <td>0.228347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824382</td>\n",
       "      <td>0.826433</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>87</td>\n",
       "      <td>0.272335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.874133</td>\n",
       "      <td>95</td>\n",
       "      <td>0.291964</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863588</td>\n",
       "      <td>0.867493</td>\n",
       "      <td>0.929859</td>\n",
       "      <td>94</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>98</td>\n",
       "      <td>0.306171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880798</td>\n",
       "      <td>0.874573</td>\n",
       "      <td>0.947884</td>\n",
       "      <td>92</td>\n",
       "      <td>0.463166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.899814</td>\n",
       "      <td>95</td>\n",
       "      <td>0.327702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884923</td>\n",
       "      <td>0.897422</td>\n",
       "      <td>0.947100</td>\n",
       "      <td>97</td>\n",
       "      <td>0.473354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.718826</td>\n",
       "      <td>92</td>\n",
       "      <td>0.174397</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704790</td>\n",
       "      <td>0.712772</td>\n",
       "      <td>0.784875</td>\n",
       "      <td>23</td>\n",
       "      <td>0.130486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>92</td>\n",
       "      <td>0.171712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.834098</td>\n",
       "      <td>0.907132</td>\n",
       "      <td>91</td>\n",
       "      <td>0.141066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.875256</td>\n",
       "      <td>91</td>\n",
       "      <td>0.272190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865223</td>\n",
       "      <td>0.869007</td>\n",
       "      <td>0.929859</td>\n",
       "      <td>83</td>\n",
       "      <td>0.399295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>80</td>\n",
       "      <td>0.309833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883068</td>\n",
       "      <td>0.888195</td>\n",
       "      <td>0.945533</td>\n",
       "      <td>96</td>\n",
       "      <td>0.458856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.899473</td>\n",
       "      <td>97</td>\n",
       "      <td>0.287374</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886827</td>\n",
       "      <td>0.896494</td>\n",
       "      <td>0.951411</td>\n",
       "      <td>85</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35_equivalent_on_perc=0.02,model=BaseModel</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>95</td>\n",
       "      <td>0.253198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705546</td>\n",
       "      <td>0.713456</td>\n",
       "      <td>0.783699</td>\n",
       "      <td>49</td>\n",
       "      <td>0.318574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36_equivalent_on_perc=0.04,model=BaseModel</td>\n",
       "      <td>0.839274</td>\n",
       "      <td>90</td>\n",
       "      <td>0.170735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824358</td>\n",
       "      <td>0.829509</td>\n",
       "      <td>0.907915</td>\n",
       "      <td>62</td>\n",
       "      <td>0.138323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37_equivalent_on_perc=0.06,model=BaseModel</td>\n",
       "      <td>0.873059</td>\n",
       "      <td>96</td>\n",
       "      <td>0.285324</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863270</td>\n",
       "      <td>0.870228</td>\n",
       "      <td>0.936129</td>\n",
       "      <td>67</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38_equivalent_on_perc=0.08,model=BaseModel</td>\n",
       "      <td>0.896446</td>\n",
       "      <td>99</td>\n",
       "      <td>0.303877</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.896446</td>\n",
       "      <td>0.947884</td>\n",
       "      <td>45</td>\n",
       "      <td>0.466301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39_equivalent_on_perc=0.1,model=BaseModel</td>\n",
       "      <td>0.900303</td>\n",
       "      <td>93</td>\n",
       "      <td>0.294991</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890880</td>\n",
       "      <td>0.897666</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>96</td>\n",
       "      <td>0.493339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>BaseModel</td>\n",
       "      <td>0</td>\n",
       "      <td>{'boost_strength': 1.5, 'boost_strength_factor...</td>\n",
       "      <td>small_dense_gsc</td>\n",
       "      <td>SGD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Experiment Name  train_acc_max  \\\n",
       "0    0_equivalent_on_perc=0.02,model=BaseModel       0.722293   \n",
       "1    1_equivalent_on_perc=0.04,model=BaseModel       0.836149   \n",
       "2    2_equivalent_on_perc=0.06,model=BaseModel       0.874426   \n",
       "3    3_equivalent_on_perc=0.08,model=BaseModel       0.894200   \n",
       "4     4_equivalent_on_perc=0.1,model=BaseModel       0.894737   \n",
       "5    5_equivalent_on_perc=0.02,model=BaseModel       0.714481   \n",
       "6    6_equivalent_on_perc=0.04,model=BaseModel       0.836588   \n",
       "7    7_equivalent_on_perc=0.06,model=BaseModel       0.872913   \n",
       "8    8_equivalent_on_perc=0.08,model=BaseModel       0.895030   \n",
       "9     9_equivalent_on_perc=0.1,model=BaseModel       0.901767   \n",
       "10  10_equivalent_on_perc=0.02,model=BaseModel       0.706425   \n",
       "11  11_equivalent_on_perc=0.04,model=BaseModel       0.838688   \n",
       "12  12_equivalent_on_perc=0.06,model=BaseModel       0.873499   \n",
       "13  13_equivalent_on_perc=0.08,model=BaseModel       0.897422   \n",
       "14   14_equivalent_on_perc=0.1,model=BaseModel       0.901572   \n",
       "15  15_equivalent_on_perc=0.02,model=BaseModel       0.711015   \n",
       "16  16_equivalent_on_perc=0.04,model=BaseModel       0.836784   \n",
       "17  17_equivalent_on_perc=0.06,model=BaseModel       0.873694   \n",
       "18  18_equivalent_on_perc=0.08,model=BaseModel       0.898399   \n",
       "19   19_equivalent_on_perc=0.1,model=BaseModel       0.905869   \n",
       "20  20_equivalent_on_perc=0.02,model=BaseModel       0.717117   \n",
       "21  21_equivalent_on_perc=0.04,model=BaseModel       0.835075   \n",
       "22  22_equivalent_on_perc=0.06,model=BaseModel       0.873303   \n",
       "23  23_equivalent_on_perc=0.08,model=BaseModel       0.893419   \n",
       "24   24_equivalent_on_perc=0.1,model=BaseModel       0.903086   \n",
       "25  25_equivalent_on_perc=0.02,model=BaseModel       0.716922   \n",
       "26  26_equivalent_on_perc=0.04,model=BaseModel       0.834977   \n",
       "27  27_equivalent_on_perc=0.06,model=BaseModel       0.874133   \n",
       "28  28_equivalent_on_perc=0.08,model=BaseModel       0.896250   \n",
       "29   29_equivalent_on_perc=0.1,model=BaseModel       0.899814   \n",
       "30  30_equivalent_on_perc=0.02,model=BaseModel       0.718826   \n",
       "31  31_equivalent_on_perc=0.04,model=BaseModel       0.837858   \n",
       "32  32_equivalent_on_perc=0.06,model=BaseModel       0.875256   \n",
       "33  33_equivalent_on_perc=0.08,model=BaseModel       0.893467   \n",
       "34   34_equivalent_on_perc=0.1,model=BaseModel       0.899473   \n",
       "35  35_equivalent_on_perc=0.02,model=BaseModel       0.717410   \n",
       "36  36_equivalent_on_perc=0.04,model=BaseModel       0.839274   \n",
       "37  37_equivalent_on_perc=0.06,model=BaseModel       0.873059   \n",
       "38  38_equivalent_on_perc=0.08,model=BaseModel       0.896446   \n",
       "39   39_equivalent_on_perc=0.1,model=BaseModel       0.900303   \n",
       "\n",
       "    train_acc_max_epoch  train_acc_min  train_acc_min_epoch  train_acc_median  \\\n",
       "0                    92       0.256079                    0          0.705961   \n",
       "1                    92       0.224685                    0          0.826238   \n",
       "2                    65       0.288595                    0          0.864466   \n",
       "3                    92       0.300410                    0          0.880163   \n",
       "4                    96       0.327995                    0          0.887194   \n",
       "5                    92       0.169905                    0          0.698662   \n",
       "6                    98       0.231081                    0          0.824187   \n",
       "7                    93       0.251343                    0          0.862465   \n",
       "8                    91       0.317547                    0          0.882873   \n",
       "9                    96       0.305146                    0          0.890562   \n",
       "10                   61       0.174202                    0          0.522776   \n",
       "11                   98       0.252856                    0          0.827361   \n",
       "12                   80       0.214530                    1          0.863563   \n",
       "13                   96       0.295821                    0          0.886437   \n",
       "14                   90       0.302217                    0          0.890831   \n",
       "15                   92       0.175471                    0          0.701299   \n",
       "16                   93       0.233083                    0          0.826018   \n",
       "17                   96       0.244751                    0          0.857802   \n",
       "18                   91       0.236989                    0          0.886144   \n",
       "19                   92       0.266771                    0          0.895127   \n",
       "20                   98       0.156625                    0          0.705180   \n",
       "21                   92       0.260668                    0          0.820940   \n",
       "22                   94       0.263988                    0          0.863099   \n",
       "23                   96       0.250952                    0          0.880871   \n",
       "24                   98       0.331511                    0          0.892344   \n",
       "25                   96       0.172542                    0          0.702544   \n",
       "26                   93       0.228347                    0          0.824382   \n",
       "27                   95       0.291964                    0          0.863588   \n",
       "28                   98       0.306171                    0          0.880798   \n",
       "29                   95       0.327702                    0          0.884923   \n",
       "30                   92       0.174397                    0          0.704790   \n",
       "31                   92       0.171712                    0          0.822478   \n",
       "32                   91       0.272190                    0          0.865223   \n",
       "33                   80       0.309833                    0          0.883068   \n",
       "34                   97       0.287374                    0          0.886827   \n",
       "35                   95       0.253198                    0          0.705546   \n",
       "36                   90       0.170735                    0          0.824358   \n",
       "37                   96       0.285324                    0          0.863270   \n",
       "38                   99       0.303877                    0          0.882092   \n",
       "39                   93       0.294991                    0          0.890880   \n",
       "\n",
       "    train_acc_last  val_acc_max  val_acc_max_epoch  val_acc_min  ...  \\\n",
       "0         0.714383     0.792712                 45     0.286050  ...   \n",
       "1         0.831169     0.905172                 65     0.305643  ...   \n",
       "2         0.870813     0.936912                 78     0.447492  ...   \n",
       "3         0.891710     0.942006                 78     0.298197  ...   \n",
       "4         0.890831     0.949451                 55     0.486677  ...   \n",
       "5         0.707450     0.781740                 85     0.137539  ...   \n",
       "6         0.830876     0.907132                 98     0.296630  ...   \n",
       "7         0.869544     0.928292                 46     0.378918  ...   \n",
       "8         0.894444     0.943182                 45     0.528997  ...   \n",
       "9         0.890196     0.949451                 32     0.391066  ...   \n",
       "10        0.688849     0.789577                 99     0.087774  ...   \n",
       "11        0.837076     0.909875                 66     0.375784  ...   \n",
       "12        0.868519     0.928292                 76     0.126567  ...   \n",
       "13        0.889806     0.943966                 92     0.464342  ...   \n",
       "14        0.890587     0.951019                 77     0.505486  ...   \n",
       "15        0.707206     0.793103                 97     0.157524  ...   \n",
       "16        0.829948     0.913793                 99     0.321317  ...   \n",
       "17        0.868909     0.929075                 63     0.359326  ...   \n",
       "18        0.890440     0.941614                 25     0.346003  ...   \n",
       "19        0.902402     0.950235                 92     0.366379  ...   \n",
       "20        0.709403     0.784875                 50     0.152038  ...   \n",
       "21        0.829704     0.911834                 73     0.404781  ...   \n",
       "22        0.869007     0.929075                 50     0.370298  ...   \n",
       "23        0.889220     0.938871                 76     0.344828  ...   \n",
       "24        0.901621     0.949843                 45     0.429075  ...   \n",
       "25        0.713505     0.792712                 74     0.145376  ...   \n",
       "26        0.826433     0.911442                 87     0.272335  ...   \n",
       "27        0.867493     0.929859                 94     0.439655  ...   \n",
       "28        0.874573     0.947884                 92     0.463166  ...   \n",
       "29        0.897422     0.947100                 97     0.473354  ...   \n",
       "30        0.712772     0.784875                 23     0.130486  ...   \n",
       "31        0.834098     0.907132                 91     0.141066  ...   \n",
       "32        0.869007     0.929859                 83     0.399295  ...   \n",
       "33        0.888195     0.945533                 96     0.458856  ...   \n",
       "34        0.896494     0.951411                 85     0.429467  ...   \n",
       "35        0.713456     0.783699                 49     0.318574  ...   \n",
       "36        0.829509     0.907915                 62     0.138323  ...   \n",
       "37        0.870228     0.936129                 67     0.465909  ...   \n",
       "38        0.896446     0.947884                 45     0.466301  ...   \n",
       "39        0.897666     0.948276                 96     0.493339  ...   \n",
       "\n",
       "    lr_gamma  lr_milestones  lr_scheduler      model  momentum  \\\n",
       "0        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "1        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "2        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "3        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "4        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "5        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "6        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "7        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "8        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "9        0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "10       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "11       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "12       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "13       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "14       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "15       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "16       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "17       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "18       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "19       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "20       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "21       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "22       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "23       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "24       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "25       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "26       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "27       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "28       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "29       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "30       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "31       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "32       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "33       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "34       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "35       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "36       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "37       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "38       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "39       0.9           60.0   MultiStepLR  BaseModel         0   \n",
       "\n",
       "                                           net_params          network  \\\n",
       "0   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "1   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "2   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "3   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "4   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "5   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "6   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "7   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "8   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "9   {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "10  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "11  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "12  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "13  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "14  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "15  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "16  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "17  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "18  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "19  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "20  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "21  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "22  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "23  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "24  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "25  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "26  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "27  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "28  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "29  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "30  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "31  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "32  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "33  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "34  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "35  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "36  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "37  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "38  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "39  {'boost_strength': 1.5, 'boost_strength_factor...  small_dense_gsc   \n",
       "\n",
       "    optim_alg  test_noise weight_decay  \n",
       "0         SGD       False         0.01  \n",
       "1         SGD       False         0.01  \n",
       "2         SGD       False         0.01  \n",
       "3         SGD       False         0.01  \n",
       "4         SGD       False         0.01  \n",
       "5         SGD       False         0.01  \n",
       "6         SGD       False         0.01  \n",
       "7         SGD       False         0.01  \n",
       "8         SGD       False         0.01  \n",
       "9         SGD       False         0.01  \n",
       "10        SGD       False         0.01  \n",
       "11        SGD       False         0.01  \n",
       "12        SGD       False         0.01  \n",
       "13        SGD       False         0.01  \n",
       "14        SGD       False         0.01  \n",
       "15        SGD       False         0.01  \n",
       "16        SGD       False         0.01  \n",
       "17        SGD       False         0.01  \n",
       "18        SGD       False         0.01  \n",
       "19        SGD       False         0.01  \n",
       "20        SGD       False         0.01  \n",
       "21        SGD       False         0.01  \n",
       "22        SGD       False         0.01  \n",
       "23        SGD       False         0.01  \n",
       "24        SGD       False         0.01  \n",
       "25        SGD       False         0.01  \n",
       "26        SGD       False         0.01  \n",
       "27        SGD       False         0.01  \n",
       "28        SGD       False         0.01  \n",
       "29        SGD       False         0.01  \n",
       "30        SGD       False         0.01  \n",
       "31        SGD       False         0.01  \n",
       "32        SGD       False         0.01  \n",
       "33        SGD       False         0.01  \n",
       "34        SGD       False         0.01  \n",
       "35        SGD       False         0.01  \n",
       "36        SGD       False         0.01  \n",
       "37        SGD       False         0.01  \n",
       "38        SGD       False         0.01  \n",
       "39        SGD       False         0.01  \n",
       "\n",
       "[40 rows x 40 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Experiment Name', 'train_acc_max', 'train_acc_max_epoch',\n",
       "       'train_acc_min', 'train_acc_min_epoch', 'train_acc_median',\n",
       "       'train_acc_last', 'val_acc_max', 'val_acc_max_epoch', 'val_acc_min',\n",
       "       'val_acc_min_epoch', 'val_acc_median', 'val_acc_last', 'val_acc_all',\n",
       "       'epochs', 'experiment_file_name', 'experiment_base_path', 'trial_time',\n",
       "       'mean_epoch_time', 'scatter_plot_dicts', 'batch_size_test',\n",
       "       'batch_size_train', 'data_dir', 'dataset_name', 'debug_small_dense',\n",
       "       'debug_sparse', 'debug_weights', 'device', 'equivalent_on_perc',\n",
       "       'learning_rate', 'lr_gamma', 'lr_milestones', 'lr_scheduler', 'model',\n",
       "       'momentum', 'net_params', 'network', 'optim_alg', 'test_noise',\n",
       "       'weight_decay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment Name                 1_equivalent_on_perc=0.04,model=BaseModel\n",
       "train_acc_max                                                    0.836149\n",
       "train_acc_max_epoch                                                    92\n",
       "train_acc_min                                                    0.224685\n",
       "train_acc_min_epoch                                                     0\n",
       "train_acc_median                                                 0.826238\n",
       "train_acc_last                                                   0.831169\n",
       "val_acc_max                                                      0.905172\n",
       "val_acc_max_epoch                                                      65\n",
       "val_acc_min                                                      0.305643\n",
       "val_acc_min_epoch                                                       0\n",
       "val_acc_median                                                   0.881661\n",
       "val_acc_last                                                      0.88127\n",
       "val_acc_all             0     0.305643\n",
       "1     0.498433\n",
       "2     0.567790\n",
       "3...\n",
       "epochs                                                                100\n",
       "experiment_file_name    /Users/mcaporale/nta/results/gsc-smalldense-20...\n",
       "experiment_base_path                                       gsc-smalldense\n",
       "trial_time                                                        13.2269\n",
       "mean_epoch_time                                                  0.132269\n",
       "scatter_plot_dicts                                                     {}\n",
       "batch_size_test                                                      1000\n",
       "batch_size_train                                                       10\n",
       "data_dir                                               ~/nta/datasets/gsc\n",
       "dataset_name                                              PreprocessedGSC\n",
       "debug_small_dense                                                    True\n",
       "debug_sparse                                                         True\n",
       "debug_weights                                                        True\n",
       "device                                                               cuda\n",
       "equivalent_on_perc                                                   0.04\n",
       "learning_rate                                                        0.01\n",
       "lr_gamma                                                              0.9\n",
       "lr_milestones                                                          60\n",
       "lr_scheduler                                                  MultiStepLR\n",
       "model                                                           BaseModel\n",
       "momentum                                                                0\n",
       "net_params              {'boost_strength': 1.5, 'boost_strength_factor...\n",
       "network                                                   small_dense_gsc\n",
       "optim_alg                                                             SGD\n",
       "test_noise                                                          False\n",
       "weight_decay                                                         0.01\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "equivalent_on_perc\n",
       "0.02    8\n",
       "0.04    8\n",
       "0.06    8\n",
       "0.08    8\n",
       "0.10    8\n",
       "Name: equivalent_on_perc, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('equivalent_on_perc')['equivalent_on_perc'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Details"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# experiment configurations\n",
    "base_exp_config = dict(\n",
    "    device=(\"cuda\" if torch.cuda.device_count() > 0 else \"cpu\"),\n",
    "    # dataset related\n",
    "    dataset_name=\"PreprocessedGSC\",\n",
    "    data_dir=\"~/nta/datasets/gsc\",\n",
    "\n",
    "    # batch_size_train=(4, 16),\n",
    "    # batch_size_test=(1000),\n",
    "    # # ----- Optimizer Related ----\n",
    "    # optim_alg=\"SGD\",\n",
    "    # momentum=0.0,\n",
    "    # learning_rate=0.01,\n",
    "    # weight_decay=1e-2,\n",
    "    # # ----- LR Scheduler Related ----\n",
    "    # lr_scheduler=\"StepLR\",\n",
    "    # lr_step_size=1,\n",
    "    # lr_gamma=0.9,\n",
    "\n",
    "    batch_size_train=(4, 16),\n",
    "    batch_size_test=1000,\n",
    "    optim_alg=\"SGD\",\n",
    "    momentum=0,  # 0.9,\n",
    "    learning_rate=0.01,  # 0.1,\n",
    "    weight_decay=0.01,  # 1e-4,\n",
    "    lr_scheduler=\"MultiStepLR\",\n",
    "    lr_milestones=[30, 60, 90],\n",
    "    lr_gamma=0.9,  # 0.1,\n",
    "\n",
    "    # additional validation\n",
    "    test_noise=False,\n",
    "    # debugging\n",
    "    debug_weights=True,\n",
    "    debug_sparse=True,\n",
    ")\n",
    "\n",
    "# ray configurations\n",
    "experiment_name = \"gsc-smalldense-2019-10-11-exp1\"\n",
    "tune_config = dict(\n",
    "    name=experiment_name,\n",
    "    num_samples=8,\n",
    "    local_dir=os.path.expanduser(os.path.join(\"~/nta/results\", experiment_name)),\n",
    "    checkpoint_freq=0,\n",
    "    checkpoint_at_end=False,\n",
    "    stop={\"training_iteration\": 100},\n",
    "    resources_per_trial={\n",
    "        \"cpu\": os.cpu_count() / 8,\n",
    "        \"gpu\": 0.5,\n",
    "    },\n",
    "    loggers=DEFAULT_LOGGERS,\n",
    "    verbose=1,\n",
    "    config=base_exp_config,\n",
    ")\n",
    "\n",
    "# define experiments\n",
    "net_params = dict(\n",
    "    boost_strength=1.5,\n",
    "    boost_strength_factor=0.9,\n",
    "    k_inference_factor=1.5,\n",
    "    duty_cycle_period=1000\n",
    ")\n",
    "experiments = {\n",
    "\n",
    "    \"gsc-smalldense\": dict(\n",
    "        model=ray.tune.grid_search([\"BaseModel\"]),\n",
    "        network=\"small_dense_gsc\",\n",
    "        net_params=net_params,\n",
    "        equivalent_on_perc=ray.tune.grid_search([\n",
    "            0.02, 0.04, 0.06, 0.08, 0.10,\n",
    "        ]),\n",
    "        debug_small_dense=True,\n",
    "    ),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Did any  trials failed?\n",
    "df[df[\"epochs\"]<100][\"epochs\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing failed or incomplete trials\n",
    "df_origin = df.copy()\n",
    "df = df_origin[df_origin[\"epochs\"]>=30]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: epochs, dtype: int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which ones failed?\n",
    "# failed, or still ongoing?\n",
    "df_origin['failed'] = df_origin[\"epochs\"]<30\n",
    "df_origin[df_origin['failed']]['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def mean_and_std(s):\n",
    "    return \"{:.3f} ± {:.3f}\".format(s.mean(), s.std())\n",
    "\n",
    "def round_mean(s):\n",
    "    return \"{:.0f}\".format(round(s.mean()))\n",
    "\n",
    "stats = ['min', 'max', 'mean', 'std']\n",
    "\n",
    "def agg(columns, filter=None, round=3):\n",
    "    if filter is None:\n",
    "        return (df.groupby(columns)\n",
    "             .agg({'val_acc_max_epoch': round_mean,\n",
    "                   'val_acc_max': stats,                \n",
    "                   'model': ['count']})).round(round)\n",
    "    else:\n",
    "        return (df[filter].groupby(columns)\n",
    "             .agg({'val_acc_max_epoch': round_mean,\n",
    "                   'val_acc_max': stats,                \n",
    "                   'model': ['count']})).round(round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Does improved weight pruning outperforms regular SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>val_acc_max_epoch</th>\n",
       "      <th colspan=\"4\" halign=\"left\">val_acc_max</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>round_mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equivalent_on_perc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>65</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>80</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.003</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>70</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.004</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>69</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.003</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>72</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   val_acc_max_epoch val_acc_max                      model\n",
       "                          round_mean         min    max   mean    std count\n",
       "equivalent_on_perc                                                         \n",
       "0.02                              65       0.782  0.793  0.788  0.005     8\n",
       "0.04                              80       0.905  0.914  0.909  0.003     8\n",
       "0.06                              70       0.928  0.937  0.931  0.004     8\n",
       "0.08                              69       0.939  0.948  0.944  0.003     8\n",
       "0.10                              72       0.947  0.951  0.950  0.001     8"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg = agg(['equivalent_on_perc'])\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalent_on_percs = df_agg.index.values\n",
    "\n",
    "val_means = df_agg['val_acc_max']['mean']\n",
    "val_means = np.array(val_means)\n",
    "val_stds = df_agg['val_acc_max']['std']\n",
    "val_stds = np.array(val_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.04 0.06 0.08 0.1 ]\n",
      "[0.788 0.909 0.931 0.944 0.95 ]\n",
      "[0.005 0.003 0.004 0.003 0.001]\n"
     ]
    }
   ],
   "source": [
    "print(equivalent_on_percs)\n",
    "print(val_means)\n",
    "print(val_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate model names\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "# d = {\n",
    "#     'DSNNWeightedMag': 'DSNN',\n",
    "#     'DSNNMixedHeb': 'SET',\n",
    "#     'SparseModel': 'Static',        \n",
    "# }\n",
    "# df_plot = df.copy()\n",
    "# df_plot['model'] = df_plot['model'].apply(lambda x, i: model_name(x, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 468,
       "width": 944
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(\n",
    "    x=equivalent_on_percs,\n",
    "    y=val_means,\n",
    "    yerr=val_stds,\n",
    "    color='k',\n",
    "    marker='*',\n",
    "    lw=0,\n",
    "    elinewidth=2,\n",
    "    capsize=2,\n",
    "    markersize=10,\n",
    "    label=\"Small-Dense Equivalents\"\n",
    ")\n",
    "# sns.scatterplot(data=df_plot, x='on_perc', y='val_acc_max', hue='model')\n",
    "# sns.lineplot(data=df, x='equivalent_on_perc', y='val_acc_max', hue='equivalent_on_perc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
