{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from torchnlp.datasets import penn_treebank_dataset\n",
    "import torch\n",
    "from torchnlp.samplers import BPTTBatchSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from rsm_samplers import MNISTSequenceSampler, ptb_pred_sequence_collate\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from importlib import reload \n",
    "from torch.utils.data import Sampler, BatchSampler\n",
    "import rsm\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from functools import reduce, partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(_repackage_hidden(v) for v in h)\n",
    "\n",
    "def activity_square(vector):\n",
    "    n = len(vector)\n",
    "    side = int(np.sqrt(n))\n",
    "    if side ** 2 < n:\n",
    "        side += 1\n",
    "    square = torch.zeros(side ** 2)\n",
    "    square[:n] = vector\n",
    "    return square.view(side, side)\n",
    "    \n",
    "def plot_act_distrs(distrs, n_labels=10, level='column'):  # level='cell'\n",
    "    col_act_avgs = []\n",
    "    n_plots = len(distrs.keys())\n",
    "    fig, axs = plt.subplots(n_plots, 1, dpi=144, gridspec_kw={'hspace': 0.7})\n",
    "    pi = 0\n",
    "    for i in range(n_labels):\n",
    "        for j in range(n_labels):\n",
    "            key = '%d-%d' % (i, j)\n",
    "            if key in distrs:\n",
    "                activity_arr = distrs[key]\n",
    "                dist = torch.stack(activity_arr)\n",
    "                col_act = dist.max(dim=2).values\n",
    "                ax = axs[pi]\n",
    "                pi += 1\n",
    "                bsz, m, n = dist.size()\n",
    "                if level == 'column':\n",
    "                    act = col_act\n",
    "                elif level == 'cell':\n",
    "                    col = col_act.view(bsz, m, 1)\n",
    "                    act = torch.cat((dist, col), 2).view(bsz, m, n + 1)\n",
    "                mean_act = act.mean(dim=0)\n",
    "                ax.imshow(mean_act.t(), origin='bottom', vmin=0, vmax=1, extent=(0, m-1, 0, n+1))\n",
    "                ax.plot([0, m-1], [n, n], linewidth=1)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(key, fontsize=5)\n",
    "    plt.show()\n",
    "    return {}\n",
    "\n",
    "def _plot_grad_flow(named_parameters):\n",
    "        '''Plots the gradients flowing through different layers in the net during training.\n",
    "        Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "\n",
    "        Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "        \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "        ave_grads = []\n",
    "        max_grads= []\n",
    "        layers = []\n",
    "        for n, p in named_parameters:\n",
    "            if(p.requires_grad) and (\"bias\" not in n):\n",
    "                layers.append(n)\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "        plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "        plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "        plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "        plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "        plt.xlim(left=0, right=len(ave_grads))\n",
    "        plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "        plt.xlabel(\"Layers\")\n",
    "        plt.ylabel(\"average gradient\")\n",
    "        plt.title(\"Gradient flow\")\n",
    "        plt.grid(True)\n",
    "        plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                    Line2D([0], [0], color=\"b\", lw=4),\n",
    "                    Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rsm_samplers\n",
    "import rsm\n",
    "reload(rsm)\n",
    "reload(rsm_samplers)\n",
    "\n",
    "from torch.utils.data import DataLoader, BatchSampler\n",
    "\n",
    "dataset = datasets.MNIST(\"~/nta/datasets\", download=True,\n",
    "                                               transform=transforms.Compose([\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                               ]),)\n",
    "\n",
    "bs=1\n",
    "m=50\n",
    "k=10\n",
    "n=3\n",
    "SEQ = [[0,1,2,3],[0,3,2,1]]\n",
    "sl = 8\n",
    "d_in = d_out = 28 ** 2\n",
    "gamma = 0.5  # Inh decay\n",
    "eps = 0.0  # Memory decay\n",
    "sampler = rsm_samplers.MNISTSequenceSampler(dataset, sequences=SEQ, randomize_sequences=True, random_mnist_images=False)\n",
    "batch_sampler = rsm_samplers.PredictiveBatchSampler(sampler, batch_size=sl * bs)\n",
    "\n",
    "collate_fn = partial(rsm_samplers.pred_sequence_collate, \n",
    "                     bsz=bs,\n",
    "                     seq_length=sl,\n",
    "                    return_inputs=True)\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_sampler=batch_sampler,\n",
    "                    collate_fn=collate_fn)\n",
    "model = rsm.RSMLayer(d_in=d_in, d_out=d_out, m=m, n=n, k=k, eps=eps, gamma=gamma, \n",
    "                     col_inhib=False,\n",
    "                     boost_strat='dc_boosting',\n",
    "                     visual_debug=False, debug=False)\n",
    "\n",
    "criterion = MSELoss()\n",
    "\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "0 loss 1.2156089842319489\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "1 loss 1.1840111017227173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1]])\n",
      "2 loss 1.161680907011032\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_b = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "phi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "psi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "hidden = (x_b, phi, psi)\n",
    "\n",
    "MAX_BATCHES = 4\n",
    "CLASSES = 10\n",
    "EPOCHS = 3\n",
    "\n",
    "condtl_column_dists = {}  # 'digit-digit' -> list of distribution arrays\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for i, (data, targets, pred_targets, input_labels) in enumerate(loader):\n",
    "        print(input_labels)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden, x_bs = model(data, hidden)\n",
    "        x_b, phi, psi = hidden\n",
    "        for x_b_batch, label_batch, target_batch in zip(x_bs, input_labels, pred_targets):\n",
    "            for _x_b, label, target in zip(x_b_batch, label_batch, target_batch):\n",
    "                digit = label.item()\n",
    "                next_digit = target.item()\n",
    "                activity = _x_b.detach().view(m, -1)\n",
    "                key = \"%d-%d\" % (digit, next_digit)\n",
    "                if key not in condtl_column_dists:\n",
    "                    condtl_column_dists[key] = []\n",
    "                condtl_column_dists[key].append(activity)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # _plot_grad_flow(model.named_parameters())\n",
    "        optimizer.step()\n",
    "        \n",
    "        hidden = _repackage_hidden(hidden)\n",
    "\n",
    "        if i >= MAX_BATCHES - 1:\n",
    "            break\n",
    "\n",
    "    print(epoch, 'loss', total_loss / (i+1))\n",
    "    condtl_column_dists = plot_act_distrs(condtl_column_dists, n_labels=4, level='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 12).reshape(2, 4, 3)\n",
    "print(a)\n",
    "values, indices = torch.topk(a, 2)\n",
    "print(indices)\n",
    "arr = a.new_zeros(a.size())  # Zeros, conserve device\n",
    "arr.scatter_(2, indices, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(corpus.train), len(corpus.valid), len(corpus.test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "batches = len(corpus.train) / batch_size\n",
    "0.25 * batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "def topk_mask(a, k, dim=0, do_softmax=False):\n",
    "    \"\"\"\n",
    "    Return a 1 for the top b elements in the last dim of a, 0 otherwise\n",
    "    \"\"\"\n",
    "    if do_softmax:\n",
    "        return softmax(a)\n",
    "    else:\n",
    "        values, indices = torch.topk(a, k)\n",
    "    arr = a.new_zeros(a.size())  # Zeros, conserve device\n",
    "    arr.scatter_(dim, indices, 1)\n",
    "    return arr\n",
    "\n",
    "a = torch.randn((3, 4))\n",
    "print(a)\n",
    "topk_mask(a, 1, dim=1, do_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LocalLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, local_features, kernel_size, stride=1, bias=True):\n",
    "        super(LocalLinear, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        fold_num = (in_features - self.kernel_size) // self.stride + 1\n",
    "        self.lc = nn.ModuleList([deepcopy(nn.Linear(kernel_size, local_features, bias=bias))\n",
    "                                 for _ in range(fold_num)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unfold(-1, size=self.kernel_size, step=self.stride)\n",
    "        fold_num = x.shape[1]\n",
    "        x = torch.cat([self.lc[i](x[:, i, :]) for i in range(fold_num)], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ActiveDendriteLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Local layer for active dendrites. Similar to a non-shared weight version of a \n",
    "    2D Conv layer.\n",
    "    \n",
    "    Note that dendrites are fully connected to input, local layer used only for connecting\n",
    "    neurons and their dendrites\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, n_cells=50, n_dendrites=3):\n",
    "        super(ActiveDendriteLayer, self).__init__()\n",
    "        self.n_cells = n_cells\n",
    "        self.n_dendrites = n_dendrites\n",
    "        \n",
    "        total_dendrites = n_dendrites * n_cells\n",
    "        self.linear_dend = nn.Linear(input_dim, total_dendrites)\n",
    "        self.linear_neuron = LocalLinear(total_dendrites, 1, n_dendrites, stride=n_dendrites)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ActiveDendriteLayer neur=%d, dend per neuron=%d\" % (self.n_cells, self.n_dendrites)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear_dend(x))\n",
    "        x = self.linear_neuron(x)\n",
    "        return x\n",
    " \n",
    "x = torch.randn(1, 5)\n",
    "print(x)\n",
    "adl = ActiveDendriteLayer(5, 4, 2)\n",
    "print(adl(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3)\n",
    "x[:, -2:] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1001001010010101101101011010'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BitwiseWordEmbedding(object):\n",
    "\n",
    "    def __init__(self, vocab_size=10000, dim=28):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dict = {}\n",
    "        self.dim = dim\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        for i in range(self.vocab_size):\n",
    "            self.embedding_dict[i] = self.embed(i)\n",
    "\n",
    "    def embed(self, i):\n",
    "        first = \"{0:b}\".format(i).zfill(self.dim // 2)\n",
    "        return first + self.inverse(first)\n",
    "\n",
    "    def inverse(self, binstr):\n",
    "        return ''.join('1' if x == '0' else '0' for x in binstr)\n",
    "\n",
    "bwe = BitwiseWordEmbedding()\n",
    "\n",
    "bwe.embed(9381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 432, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload \n",
    "import viz_util\n",
    "reload(viz_util)\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from io import BytesIO\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ax, fig = viz_util.plot_confusion_matrix(np.array([1,2,3]), np.array([1,2,0]), ['0', '1', '2', '3'])\n",
    "\n",
    "img = viz_util.fig2img(fig)\n",
    "\n",
    "print(img.shape)\n",
    "plt.imsave('test.png', img, format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgordon/miniconda3/envs/standard/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0, 5).expand((3, 6)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2177, 0.5582, 0.1910],\n",
      "         [0.0793, 0.9190, 0.8308],\n",
      "         [0.4444, 0.2490, 0.6382],\n",
      "         [0.4885, 0.0823, 0.4100],\n",
      "         [0.4710, 0.3245, 0.6746]],\n",
      "\n",
      "        [[0.0987, 0.9523, 0.1822],\n",
      "         [0.0910, 0.5141, 0.2099],\n",
      "         [0.9616, 0.5538, 0.5057],\n",
      "         [0.1261, 0.0208, 0.4588],\n",
      "         [0.0423, 0.1273, 0.3052]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0],\n",
       "         [0, 1, 1],\n",
       "         [1, 0, 1],\n",
       "         [1, 0, 1],\n",
       "         [1, 0, 1]],\n",
       "\n",
       "        [[0, 1, 1],\n",
       "         [0, 1, 1],\n",
       "         [1, 1, 0],\n",
       "         [1, 0, 1],\n",
       "         [0, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nupic.torch.functions import KWinners\n",
    "\n",
    "kw = KWinners.apply\n",
    "\n",
    "bsz = 2\n",
    "m = 5\n",
    "n = 3\n",
    "\n",
    "k = 2\n",
    "\n",
    "a = torch.rand(bsz, m, n)\n",
    "print(a)\n",
    "kw(a.view(bsz * m, n), 0, k, 0).view(bsz, m, n) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2309,  0.2413,  0.0531,  0.1007, -0.1583],\n",
      "        [ 0.1270,  0.2542, -0.0928,  0.0849, -0.4191],\n",
      "        [ 0.2453,  0.2738,  0.1485,  0.0858, -0.2552]],\n",
      "       grad_fn=<AddmmBackward>) torch.Size([3, 5])\n",
      "tensor([[ 0.2309,  0.2309,  0.2309,  0.2309,  0.2413,  0.2413,  0.2413,  0.2413,\n",
      "          0.0531,  0.0531,  0.0531,  0.0531,  0.1007,  0.1007,  0.1007,  0.1007,\n",
      "         -0.1583, -0.1583, -0.1583, -0.1583],\n",
      "        [ 0.1270,  0.1270,  0.1270,  0.1270,  0.2542,  0.2542,  0.2542,  0.2542,\n",
      "         -0.0928, -0.0928, -0.0928, -0.0928,  0.0849,  0.0849,  0.0849,  0.0849,\n",
      "         -0.4191, -0.4191, -0.4191, -0.4191],\n",
      "        [ 0.2453,  0.2453,  0.2453,  0.2453,  0.2738,  0.2738,  0.2738,  0.2738,\n",
      "          0.1485,  0.1485,  0.1485,  0.1485,  0.0858,  0.0858,  0.0858,  0.0858,\n",
      "         -0.2552, -0.2552, -0.2552, -0.2552]], grad_fn=<IndexSelectBackward>)\n",
      "tensor([[ 0.1270,  0.1270,  0.1270,  0.1270],\n",
      "        [ 0.2542,  0.2542,  0.2542,  0.2542],\n",
      "        [-0.0928, -0.0928, -0.0928, -0.0928],\n",
      "        [ 0.0849,  0.0849,  0.0849,  0.0849],\n",
      "        [-0.4191, -0.4191, -0.4191, -0.4191]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "sl = 2\n",
    "bsz = 3\n",
    "m = 5\n",
    "n = 4\n",
    "d_in = 10\n",
    "\n",
    "x = torch.rand((sl, bsz, d_in))\n",
    "\n",
    "x_a = x[0, :]  # first item\n",
    "\n",
    "A = torch.nn.Linear(d_in, m)\n",
    "\n",
    "u = A(x_a)\n",
    "print(u, u.size())\n",
    "z = u.repeat_interleave(n, 1)\n",
    "\n",
    "print(z)\n",
    "\n",
    "first_z_batch = z[1]\n",
    "print(first_z_batch.view(m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import rsm_k_winners\n",
    "reload(rsm_k_winners)\n",
    "\n",
    "def run_kwin(size=50, scatter=True):\n",
    "    return rsm_k_winners.KWinners.apply(torch.rand(size, size), 0, 10, 0, scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4548, 0.8208, 0.3500,  ..., 0.0000, 0.0000, 0.2274],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.8647, 0.0963,  ..., 0.7562, 0.0000, 0.6054],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3596, 0.8424, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4383, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.6986]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_kwin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scatter 0.9094837090015062\n",
      "no_scatter 10.072980703000212\n"
     ]
    }
   ],
   "source": [
    "from timeit import Timer\n",
    "\n",
    "t = Timer(lambda: run_kwin(scatter=True))\n",
    "print('scatter', t.timeit(number=10000))\n",
    "\n",
    "t = Timer(lambda: run_kwin(scatter=False))\n",
    "print('no_scatter', t.timeit(number=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1703, 0.4110, 0.3670],\n",
      "        [0.3609, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.4454]])\n",
      "tensor([[2, 1],\n",
      "        [2, 1],\n",
      "        [0, 1]])\n",
      "tensor([[0.0000, 0.4110, 0.3670],\n",
      "        [0.0000, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.0000]])\n",
      "tensor([[0.0000, 0.4110, 0.3670],\n",
      "        [0.0000, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rsm_k_winners\n",
    "reload(rsm_k_winners)\n",
    "\n",
    "a = torch.rand(3, 3)\n",
    "\n",
    "print(a)\n",
    "\n",
    "res_scatter = rsm_k_winners.KWinners.apply(a.clone(), 0, 2, 0, True)\n",
    "res_no_scatter = rsm_k_winners.KWinners.apply(a.clone(), 0, 2, 0, False)\n",
    "\n",
    "print(res_scatter)\n",
    "print(res_no_scatter)\n",
    "bool(torch.all(torch.eq(res_scatter, res_no_scatter)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 8., 9., 7.],\n",
      "        [0., 9., 1., 8.],\n",
      "        [0., 4., 3., 6.],\n",
      "        [0., 5., 2., 3.],\n",
      "        [0., 1., 7., 5.],\n",
      "        [1., 0., 5., 4.],\n",
      "        [1., 6., 6., 9.],\n",
      "        [1., 7., 0., 0.],\n",
      "        [1., 3., 8., 1.],\n",
      "        [1., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_subsequences(start_digits=[0, 1], digits=10, length=4):\n",
    "    seq = torch.zeros(digits, length)\n",
    "    reps = int(np.ceil(digits / len(start_digits)))\n",
    "    first_col = torch.repeat_interleave(torch.tensor(start_digits), reps, 0)\n",
    "    seq[:, 0] = first_col[:digits]\n",
    "    for i in range(1, length):\n",
    "        column = torch.arange(digits)\n",
    "        idxs = torch.randperm(digits)\n",
    "        seq[:, i] = column[idxs]\n",
    "    print(seq)\n",
    "\n",
    "\n",
    "generate_subsequences(digits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 20, 784]) 3 torch.Size([8, 20, 32])\n",
      "tensor([[[ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         ...,\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028]],\n",
      "\n",
      "        [[ 0.0951,  0.1785, -0.2497,  ..., -0.1264,  0.4125, -0.2198],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         ...,\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.0951,  0.1785, -0.2497,  ..., -0.1264,  0.4125, -0.2198]],\n",
      "\n",
      "        [[-0.0182,  0.1280, -0.1884,  ..., -0.1021,  0.3155, -0.3728],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         ...,\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0182,  0.1280, -0.1884,  ..., -0.1021,  0.3155, -0.3728]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0954,  0.1780, -0.2471,  ..., -0.1273,  0.4118, -0.2232],\n",
      "         [ 0.0813,  0.1204, -0.2180,  ..., -0.0940,  0.3946, -0.2014],\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         ...,\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         [ 0.1987,  0.1008, -0.1878,  ..., -0.2652,  0.4314, -0.5043]],\n",
      "\n",
      "        [[ 0.0270,  0.0948, -0.1481,  ..., -0.0955,  0.3490, -0.3901],\n",
      "         [ 0.0272,  0.0946, -0.1480,  ..., -0.0954,  0.3491, -0.3902],\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         ...,\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         [ 0.0264,  0.0954, -0.1488,  ..., -0.0956,  0.3485, -0.3899]],\n",
      "\n",
      "        [[ 0.1856,  0.0515, -0.1618,  ..., -0.2356,  0.4160, -0.4847],\n",
      "         [ 0.2112,  0.0833, -0.1967,  ..., -0.2737,  0.4383, -0.5155],\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         ...,\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         [ 0.0813,  0.1205, -0.2180,  ..., -0.0941,  0.3946, -0.2015]]],\n",
      "       grad_fn=<DifferentiableGraphBackward>) 1.2037055492401123\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(sl, bs, 28**2)\n",
    "\n",
    "x_b = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "phi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "psi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "hidden = (x_b, phi, psi)\n",
    "\n",
    "del model \n",
    "model = torch.jit.load(\"/Users/jgordon/nta/results/rsm_jit.pt\")\n",
    "\n",
    "# print(model.graph)\n",
    "\n",
    "inputs, targets, pred_target, input_label = next(iter(loader))\n",
    "\n",
    "out, hidden, x_bs = model(inputs, hidden)\n",
    "print(out.size(), len(hidden), x_bs.size())\n",
    "total_loss = 0.0\n",
    "loss = criterion(out, targets)\n",
    "loss.backward()\n",
    "total_loss += loss.item()\n",
    "optimizer.step()\n",
    "print(out, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.values>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(5)\n",
    "\n",
    "torch.max(a.sum(), torch.Tensor(1)).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
