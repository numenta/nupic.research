{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.datasets import penn_treebank_dataset\n",
    "import torch\n",
    "from torchnlp.samplers import BPTTBatchSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from rsm_samplers import MNISTSequenceSampler, ptb_pred_sequence_collate\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from importlib import reload \n",
    "from torch.utils.data import Sampler, BatchSampler\n",
    "import rsm\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from functools import reduce, partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(_repackage_hidden(v) for v in h)\n",
    "\n",
    "def activity_square(vector):\n",
    "    n = len(vector)\n",
    "    side = int(np.sqrt(n))\n",
    "    if side ** 2 < n:\n",
    "        side += 1\n",
    "    square = torch.zeros(side ** 2)\n",
    "    square[:n] = vector\n",
    "    return square.view(side, side)\n",
    "    \n",
    "def plot_act_distrs(distrs, n_labels=10, level='column'):  # level='cell'\n",
    "    col_act_avgs = []\n",
    "    n_plots = len(distrs.keys())\n",
    "    fig, axs = plt.subplots(n_plots, 1, dpi=144, gridspec_kw={'hspace': 0.7})\n",
    "    pi = 0\n",
    "    for i in range(n_labels):\n",
    "        for j in range(n_labels):\n",
    "            key = '%d-%d' % (i, j)\n",
    "            if key in distrs:\n",
    "                activity_arr = distrs[key]\n",
    "                dist = torch.stack(activity_arr)\n",
    "                col_act = dist.max(dim=2).values\n",
    "                ax = axs[pi]\n",
    "                pi += 1\n",
    "                bsz, m, n = dist.size()\n",
    "                if level == 'column':\n",
    "                    act = col_act\n",
    "                elif level == 'cell':\n",
    "                    col = col_act.view(bsz, m, 1)\n",
    "                    act = torch.cat((dist, col), 2).view(bsz, m, n + 1)\n",
    "                mean_act = act.mean(dim=0)\n",
    "                ax.imshow(mean_act.t(), origin='bottom', extent=(0, m-1, 0, n+1))\n",
    "                ax.plot([0, m-1], [n, n], linewidth=1)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(key, fontsize=5)\n",
    "    plt.show()\n",
    "    return {}\n",
    "\n",
    "def _plot_grad_flow(named_parameters):\n",
    "        '''Plots the gradients flowing through different layers in the net during training.\n",
    "        Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "\n",
    "        Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "        \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "        ave_grads = []\n",
    "        max_grads= []\n",
    "        layers = []\n",
    "        for n, p in named_parameters:\n",
    "            if(p.requires_grad) and (\"bias\" not in n):\n",
    "                layers.append(n)\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "        plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "        plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "        plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "        plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "        plt.xlim(left=0, right=len(ave_grads))\n",
    "        plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "        plt.xlabel(\"Layers\")\n",
    "        plt.ylabel(\"average gradient\")\n",
    "        plt.title(\"Gradient flow\")\n",
    "        plt.grid(True)\n",
    "        plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                    Line2D([0], [0], color=\"b\", lw=4),\n",
    "                    Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rsm_samplers\n",
    "import rsm\n",
    "reload(rsm)\n",
    "reload(rsm_samplers)\n",
    "\n",
    "from torch.utils.data import DataLoader, BatchSampler\n",
    "\n",
    "dataset = datasets.MNIST(\"~/nta/datasets\", download=True,\n",
    "                                               transform=transforms.Compose([\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                               ]),)\n",
    "\n",
    "bs=20\n",
    "m=8\n",
    "k=2\n",
    "n=4\n",
    "SEQ = [[0,1,2,3],[0,3,2,1]]\n",
    "sl = 8\n",
    "d_in = d_out = 28 ** 2\n",
    "sampler = rsm_samplers.MNISTSequenceSampler(dataset, sequences=SEQ, randomize_sequences=True, random_mnist_images=False)\n",
    "batch_sampler = rsm_samplers.PredictiveBatchSampler(sampler, batch_size=sl * bs)\n",
    "\n",
    "collate_fn = partial(rsm_samplers.pred_sequence_collate, \n",
    "                     bsz=bs,\n",
    "                     seq_length=sl,\n",
    "                    return_inputs=True)\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_sampler=batch_sampler,\n",
    "                    collate_fn=collate_fn)\n",
    "model = rsm.RSMLayer(d_in=d_in, d_out=d_out, m=m, n=n, k=k, visual_debug=False, debug=False)\n",
    "\n",
    "criterion = MSELoss()\n",
    "\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(sl, bs, 28**2)\n",
    "\n",
    "x_b = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "phi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "psi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "hidden = (x_b, phi, psi)\n",
    "\n",
    "traced_rsm = torch.jit.trace(model, (inputs, hidden))\n",
    "torch.jit.save(traced_rsm, '/Users/jgordon/nta/results/rsm_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 0.9271140654881795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 0.9269945780436198\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAAHjCAYAAABrduLdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAO1ElEQVR4nO2da4xU9RnGn5fZ5aIgIHjhpiAgFYuCCFWjJta0XmjUtLFVG6uEtLWmUWz7wdYPDZpYtWpNetWo1bZotbGxrSJCjGlpvYAocpGyclNQlMuyoqCwl7cfZrZdtu/ZnWcye/6z8fklE2feOQ5vfrycOWfm/J8xd4cojz6pG+hNSBaBZBFIFoFkEUgWgWQRSBaBZBFIFoFkEUgWgWQRJJVlZueb2TozW29mN2Zss9DMmszsqbz760wyWWZWAPBLABcAmAzgcjObHGz6UwBX5tlbFiknayaA9e6+0d0PAPgjgIs7b+TuzwH4MO/mIlLKGgVgS4fHW0u1mkU7eIKUst4BMKbD49EAdpjZitLtokR9ZVKX8M9eBmCimY1DUdxlAK5w93kJe+qSZLLcvcXMvgvgWQAFAA+6+5rO25nZEgCfATDQzLYCmOPuz+bbbakXfbtTPtrBE0gWgWQRSBaBZBFIFoFkEUgWgWQRSBaBZBFUfCL9hT6XhieVH188M9z+0Lc+CuvPLHgkrD+5d2BYv+e6y8N6v2eWhfWWc6eH9ecX32jhE12gySKQLALJIpAsgoo//Bt749O9+lPDzbfN0g6+J6l4srIOHWzGlHB7X7YqrK+/57SwXrc3/osf//D2sN7asCGsFyaMC+sLG+7QZPUkkkUgWQSSRSBZBFX/RjrrXa8wZHBYt+b4TWnsTS+G9Vayn9b1m8j/IxtNFoFkEUgWgWQRSBZBbtdntTZ9ENb7NXKnaIWjjoxf//34nLGaaLIIJItAsggki0CyCCSLoOqHDnXjjg3rXoj/XpoHxR9rb7zt9LA+8f734j/4/bhcOH58/EQFaLIIJItAsggki0CyCCSLQAudCDRZBJJFIFkEkkWQXFZ3qSFmdqyZvVpaZL7GzK5J0ScAwN2T3VBcG70BwHEA+gJ4HcDkTtv0BdCvdH8ggM0ARqboN/VkdZsa4u4H3H1/6WE/JPzXkFpWWakhZjbGzFaWtr3d3d/Nqb+DSC2rLNx9i7ufBGACgKvM7KgUfaSWRaWGlCZqNYCzcuzxoAZS7uDrAGwEMA7/28Gf2Gmb0QAGlO4PBdAAYEqKflPGq5SbGnICgLvMzAEYgDvdPb4IrIfRiTRB6n1Wr0KyCCSLQLIIJItAsggki0CyCCSLQLIIqh6C8dGlnwu3H/xGU1hfsPixsP7XvYeE9buv+3pYVwhGjSFZBJJFIFkEkkWgxBACTRZB1RNDMDNODMHS+GPzjXfEl3C31cUvP+nenWG9dd36sJ51affCf9+myepJJItAsggki0CyCKr/jXTGu15h6NCwnrVGetRtVUoMycjVqgRNFoFkEUgWgWQRSBZBfokhu3eH9X0jufe3wvBh8evv3EX3xKLJIpAsAskikCwCySKQLIKqHzoUJk0I6/bJ/rBe/2H89/X2j88I6+Pmb4v/4IxDh6wg6krQZBFIFoFkEUgWgWQRSBaBFjoRaLIIJItAsgiSyjKzB81su5mt7mKbLkMyciXxGumzAZwCYHXG892GZOR5SzpZ7v4PAI1dbNJtSEae1Po+q6yQjLyodVk1RdKogs6Y2RgAfys9/A2K+6jOIRnv5N1XOzUly923AJja/tjM6gBMNLNxKEq6DMAVidpLfujwKIAXAUwys61mNqfj8+7eAqA9JGMtgMeDkIzc0LkhgXbwBJJFIFkEkkUgWQSSRSBZBJJFIFkEkkVQ9RCMqa/F26/+cvx7PE//6y9hfdaZl4T1zZeNDOujb30hrL9/XXw1zsp7btDizJ5Esggki0CyCCSLQCEYBJosgoqPsybe8VBY33DnaWF9/A9eCuvvXR8fB42avy6sf3JKfPVx/aJXwnrbWdPCOjAro56NJotAsggki0CyCCSLoOpf32e962WFYDQPjF8naxlv/SJueW+fJRkfg1SAJotAsggki0CyCCSLIHkIxoAd5IcXlvFhQQ6XTmmyCCSLQLIIJItAsggki6Dqhw67vhlnJR/5ZJx93DwwPhTIOvHed3ocstFvQcZvWHw+/g2LStBkEUgWgWQRSBaBZBFIFoEWOhFosggki0CyCFKvZO0yBMPMxpjZ82b2hpmtMbPr8+7xoH5S7uDN7GwAHwH4nbt/Nnh+BIAR7v6qmQ0CsBzAJe7+Rs6tAkg8Wd2FYLj7Nnd/tXT/QxTXSSvXoTvMbCyAaQBeTtVDr5BlZgMBPAFgrrvvSdVHTckq7dBXlG7XlGr1KIqa7+5/TtlfrYdgGIAHAKx197uTNdZO4kioRwFsA9CMYijPnE7PnwnAAawEsKJ0uzBVvzo3JKipfVatI1kEkkUgWQSSRSBZBJJFIFkEkkUgWQSSRVD1xJDt18YrU0c8EV9ytOC1RWF9ys+uDev7Tvo4rE+4Ml6jUzf2mLD+zMa7tEa6J5EsAskikCwChWAQaLIIKp6srEOH/RfOCLfPupp44+3x1c3HLDoQ1lsGFMJ6/6eWhvXCkMFhfWHj/ZqsnkSyCCSLQLIIJIug6l/fZ73rWb9+Yb1+T/ymVPfc8rhO9tPa9AH5f2SjySKQLALJIpAsAskiyO1iNt8f/5x782Du3LTPIYeE9bZ9++ieWDRZBJJFIFkEkkUgWQSSRVD1Q4c+J58Q1u2td8N61ol08xdPDevvT+8b1kf/JP4Ni6wwjUrQZBFIFoFkEUgWgWQRSBaBFjoRaLIIJItAsggkiyB1YkhZiSDdJYvkRerEkLISQbpLFsmL1IkhZSWCdJcskhc1s8+qhUSQ7qgJWbWSCNIdyWV1TgSJUkNqhaSJIVEiSOfUkJoicWJIWYkg6CZZRIkhNUjyfVZvQrIIJItAsggki0CyCCSLQLIIJItAsgiqHoJRN+LocPu908aE9cnzVoX1NfNOCut/v+++sH7eyPjc+1sNG8P6pROWayVrTyJZBJJFIFkEkkWgxBACTRZBxcdZE+94KKxnJXRkrVXec8VpYX3I6qawvm7OkLif618K65tviRNJgFkZ9Ww0WQSSRSBZBJJFIFkEVc/PyqJwwsSw3jh9WFgf/If43a1aLG77k46zehLJIpAsAskikCyC3C5ma137Zlhvmzmceh2ri1v2lha6JxZNFoFkEUgWgWQRSBaBZBFUPzEkIwzMJ40L682D4vPZwqQJYX3t9+IEkOO/zQVdV4Imi0CyCCSLQLIIJItAsgi00IlAk0UgWQSSRVDzIRhm1t/MlprZ66Vt5qXoFUDyZb8jAJxSuj8IQAOAyZ22MQADS/frUYwyOC1FvzUfguFFPio9rC/dkryF18w+q6sQDDMrmNkKANsBLHb3JEEZNSGruxAMd29196kARgOYaWZJ8miSy2JCMNy9CcDzAM5P0mvKI/hSCMbDABrdfW7GNkcAaHb3JjMbAGARgNvd/akcWy32kljWmQCWAFgFoK1U/pG7L+iwzUkoCi2g+C/hcXe/Oe9eAZ0bUiTfZ/UmJItAsggki0CyCCSLQLIIJItAsggki6DqIRj7Z8U/537IknVhfccjcWhG/wfjq2WW/OLesJ4VgvHQ2/8M66NGb9NylJ5Esggki0CyCCSLQCEYBJosgqqHYNj0E8O6L18T1htnx1cTD1++O6w3zI5DMCbcEC8TbvjVzLCuEIweRrIIJItAsggkiyC3EIys5bp7vhL/qu+gxxSC0auRLALJIpAsAskiyC0EIyukovlQ7k2p4bfTw/rxs5fTPbFosggki0CyCCSLQLIIJIug6ocOdWOPCett23eG9fp98fl4n5NPCOuDX+tH9bPhzji7uRI0WQSSRSBZBJJFIFkEkkWghU4EmiwCySKQLILUIRhlBVyY2VVm9mbpdlXeff6XxCEY3QZcADgcwMbSf4eW7g/9NIZglBNwcR6KWQ6N7r4bwGIkWn2ffJ9VRsDFKABbOjzeik6pInmRXFatBFyUQ3JZ7XQIuJjVIQTjIgDvAOj4g66jS7X8SbyDPwLAkNL9AShmPHwp2MFvQnHnPrR0//AU/eb2JWsGIwA8bGYdAy4OSgJx90YzuwVAex7wze7emHOfAHRuSFEz+6zegGQRSBaBZBFIFoFkEUgWgWQRSBaBZBFIFkHVE0Pqjj4q3H7H+ceF9aW3/jqsz5pxYVjfdU58SVPWD97uuTy+5Ojl+d/X2p2eRLIIJItAsggUgkGgySKoeghGYcjgsN7a9EFYb/pGHIIx7Mk4NKNt4piwnhWyYTOmhHWFYPQwkkUgWQSSRSBZBFX/RjrrXa9u3LFh3Vrjw7XWPf/3IylFMt71svBlq6jtu0KTRSBZBJJFIFkEkkWQ2/VZLZveCuv7L+AuD/XTTw7r9uLrdE8smiwCySKQLALJIpAsAskiqPqhQ5/+/cP6x+fEH++2HBq/TuGww+Indn4Yllsz+rFpcdZzJWiyCCSLQLIIJItAsggki0ALnQg0WQSSRSBZBJJFUPOJIWY21cxeLD2/0sy+lqJXAMkXlJeTGHI8gIml+yMBbENpEfqnakG5Fw10mRji7g0d7r9rZttRXLXflFef7STfZ5WRGNJx25kA+gLYkFd/HUkuy8tMDDGzEQB+D2C2u7fl2WM7yWW149mJITCzwwA8DeAmd+/Z35jppslaTwzpC+A5AHNT9pp8B48yEkMAfBXA2QCGmdnVpdrV7r4ivzaL6ESaoGb2Wb0BySKQLALJIpAsAskikCwCySKQLALJIqh+CEbG7+7sPCu+Kvnl2+MQjJk//E5YP+K5t8N6y9Y4urRuxNFh/Zl3fq410j2JZBFIFoFkEUgWgRJDCDRZBBVPVtZxVmH4sHD71p27wvp7c88I60ct3RvW61Zvil8/Y0111iXiC5se0GT1JJJFIFkEkkUgWQTVTwzJeNezU+NfiPFC/Dr2QrzmOWtBU2Y/WckjFaDJIpAsAskikCwCySLI7fosf2V1WG87Nz43zMLq+8av33yA7olFk0UgWQSSRSBZBJJFIFkEVT90yPoYt3na+LB+YEj8sbZNj5M+rCH++j7r0KHPoEFhvRI0WQSSRSBZBJJFIFkEkkWghU4EmiwCySKQLALJIpAsAskikCwCySKQLALJIpAsAskikCyC/wAWPbtXjTiD5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hidden = model.init_hidden(bs)\n",
    "\n",
    "model = torch.jit.load('/Users/jgordon/nta/results/rsm_jit.pt')\n",
    "\n",
    "MAX_BATCHES = 15\n",
    "CLASSES = 10\n",
    "EPOCHS = 2\n",
    "\n",
    "condtl_column_dists = {}  # 'digit-digit' -> list of distribution arrays\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for i, (data, targets, pred_targets, input_labels) in enumerate(loader):\n",
    "#         print(targets.size())\n",
    "#         for img in targets[:, 0]:\n",
    "#             plt.imshow(img.view(28, 28))\n",
    "#             plt.show()\n",
    "#         print('p', pred_targets)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden, x_bs = model(data, hidden)\n",
    "        x_b, phi, psi = hidden\n",
    "        for x_b_batch, label_batch, target_batch in zip(x_bs, input_labels, pred_targets):\n",
    "            for _x_b, label, target in zip(x_b_batch, label_batch, target_batch):\n",
    "                digit = label.item()\n",
    "                next_digit = target.item()\n",
    "                activity = _x_b.detach().view(m, -1)\n",
    "                key = \"%d-%d\" % (digit, next_digit)\n",
    "                if key not in condtl_column_dists:\n",
    "                    condtl_column_dists[key] = []\n",
    "                condtl_column_dists[key].append(activity)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # _plot_grad_flow(model.named_parameters())\n",
    "        optimizer.step()\n",
    "        \n",
    "        hidden = _repackage_hidden(hidden)\n",
    "\n",
    "        if i >= MAX_BATCHES - 1:\n",
    "            break\n",
    "\n",
    "    print(epoch, 'loss', total_loss / (i+1))\n",
    "#     condtl_column_dists = plot_act_distrs(condtl_column_dists, n_labels=4, level='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 12).reshape(2, 4, 3)\n",
    "print(a)\n",
    "values, indices = torch.topk(a, 2)\n",
    "print(indices)\n",
    "arr = a.new_zeros(a.size())  # Zeros, conserve device\n",
    "arr.scatter_(2, indices, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(corpus.train), len(corpus.valid), len(corpus.test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "batches = len(corpus.train) / batch_size\n",
    "0.25 * batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "def topk_mask(a, k, dim=0, do_softmax=False):\n",
    "    \"\"\"\n",
    "    Return a 1 for the top b elements in the last dim of a, 0 otherwise\n",
    "    \"\"\"\n",
    "    if do_softmax:\n",
    "        return softmax(a)\n",
    "    else:\n",
    "        values, indices = torch.topk(a, k)\n",
    "    arr = a.new_zeros(a.size())  # Zeros, conserve device\n",
    "    arr.scatter_(dim, indices, 1)\n",
    "    return arr\n",
    "\n",
    "a = torch.randn((3, 4))\n",
    "print(a)\n",
    "topk_mask(a, 1, dim=1, do_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LocalLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, local_features, kernel_size, stride=1, bias=True):\n",
    "        super(LocalLinear, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        fold_num = (in_features - self.kernel_size) // self.stride + 1\n",
    "        self.lc = nn.ModuleList([deepcopy(nn.Linear(kernel_size, local_features, bias=bias))\n",
    "                                 for _ in range(fold_num)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unfold(-1, size=self.kernel_size, step=self.stride)\n",
    "        fold_num = x.shape[1]\n",
    "        x = torch.cat([self.lc[i](x[:, i, :]) for i in range(fold_num)], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ActiveDendriteLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Local layer for active dendrites. Similar to a non-shared weight version of a \n",
    "    2D Conv layer.\n",
    "    \n",
    "    Note that dendrites are fully connected to input, local layer used only for connecting\n",
    "    neurons and their dendrites\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, n_cells=50, n_dendrites=3):\n",
    "        super(ActiveDendriteLayer, self).__init__()\n",
    "        self.n_cells = n_cells\n",
    "        self.n_dendrites = n_dendrites\n",
    "        \n",
    "        total_dendrites = n_dendrites * n_cells\n",
    "        self.linear_dend = nn.Linear(input_dim, total_dendrites)\n",
    "        self.linear_neuron = LocalLinear(total_dendrites, 1, n_dendrites, stride=n_dendrites)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ActiveDendriteLayer neur=%d, dend per neuron=%d\" % (self.n_cells, self.n_dendrites)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear_dend(x))\n",
    "        x = self.linear_neuron(x)\n",
    "        return x\n",
    " \n",
    "x = torch.randn(1, 5)\n",
    "print(x)\n",
    "adl = ActiveDendriteLayer(5, 4, 2)\n",
    "print(adl(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3)\n",
    "x[:, -2:] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1001001010010101101101011010'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BitwiseWordEmbedding(object):\n",
    "\n",
    "    def __init__(self, vocab_size=10000, dim=28):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dict = {}\n",
    "        self.dim = dim\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        for i in range(self.vocab_size):\n",
    "            self.embedding_dict[i] = self.embed(i)\n",
    "\n",
    "    def embed(self, i):\n",
    "        first = \"{0:b}\".format(i).zfill(self.dim // 2)\n",
    "        return first + self.inverse(first)\n",
    "\n",
    "    def inverse(self, binstr):\n",
    "        return ''.join('1' if x == '0' else '0' for x in binstr)\n",
    "\n",
    "bwe = BitwiseWordEmbedding()\n",
    "\n",
    "bwe.embed(9381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 432, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload \n",
    "import viz_util\n",
    "reload(viz_util)\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from io import BytesIO\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ax, fig = viz_util.plot_confusion_matrix(np.array([1,2,3]), np.array([1,2,0]), ['0', '1', '2', '3'])\n",
    "\n",
    "img = viz_util.fig2img(fig)\n",
    "\n",
    "print(img.shape)\n",
    "plt.imsave('test.png', img, format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgordon/miniconda3/envs/standard/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0, 5).expand((3, 6)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2177, 0.5582, 0.1910],\n",
      "         [0.0793, 0.9190, 0.8308],\n",
      "         [0.4444, 0.2490, 0.6382],\n",
      "         [0.4885, 0.0823, 0.4100],\n",
      "         [0.4710, 0.3245, 0.6746]],\n",
      "\n",
      "        [[0.0987, 0.9523, 0.1822],\n",
      "         [0.0910, 0.5141, 0.2099],\n",
      "         [0.9616, 0.5538, 0.5057],\n",
      "         [0.1261, 0.0208, 0.4588],\n",
      "         [0.0423, 0.1273, 0.3052]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0],\n",
       "         [0, 1, 1],\n",
       "         [1, 0, 1],\n",
       "         [1, 0, 1],\n",
       "         [1, 0, 1]],\n",
       "\n",
       "        [[0, 1, 1],\n",
       "         [0, 1, 1],\n",
       "         [1, 1, 0],\n",
       "         [1, 0, 1],\n",
       "         [0, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nupic.torch.functions import KWinners\n",
    "\n",
    "kw = KWinners.apply\n",
    "\n",
    "bsz = 2\n",
    "m = 5\n",
    "n = 3\n",
    "\n",
    "k = 2\n",
    "\n",
    "a = torch.rand(bsz, m, n)\n",
    "print(a)\n",
    "kw(a.view(bsz * m, n), 0, k, 0).view(bsz, m, n) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2309,  0.2413,  0.0531,  0.1007, -0.1583],\n",
      "        [ 0.1270,  0.2542, -0.0928,  0.0849, -0.4191],\n",
      "        [ 0.2453,  0.2738,  0.1485,  0.0858, -0.2552]],\n",
      "       grad_fn=<AddmmBackward>) torch.Size([3, 5])\n",
      "tensor([[ 0.2309,  0.2309,  0.2309,  0.2309,  0.2413,  0.2413,  0.2413,  0.2413,\n",
      "          0.0531,  0.0531,  0.0531,  0.0531,  0.1007,  0.1007,  0.1007,  0.1007,\n",
      "         -0.1583, -0.1583, -0.1583, -0.1583],\n",
      "        [ 0.1270,  0.1270,  0.1270,  0.1270,  0.2542,  0.2542,  0.2542,  0.2542,\n",
      "         -0.0928, -0.0928, -0.0928, -0.0928,  0.0849,  0.0849,  0.0849,  0.0849,\n",
      "         -0.4191, -0.4191, -0.4191, -0.4191],\n",
      "        [ 0.2453,  0.2453,  0.2453,  0.2453,  0.2738,  0.2738,  0.2738,  0.2738,\n",
      "          0.1485,  0.1485,  0.1485,  0.1485,  0.0858,  0.0858,  0.0858,  0.0858,\n",
      "         -0.2552, -0.2552, -0.2552, -0.2552]], grad_fn=<IndexSelectBackward>)\n",
      "tensor([[ 0.1270,  0.1270,  0.1270,  0.1270],\n",
      "        [ 0.2542,  0.2542,  0.2542,  0.2542],\n",
      "        [-0.0928, -0.0928, -0.0928, -0.0928],\n",
      "        [ 0.0849,  0.0849,  0.0849,  0.0849],\n",
      "        [-0.4191, -0.4191, -0.4191, -0.4191]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "sl = 2\n",
    "bsz = 3\n",
    "m = 5\n",
    "n = 4\n",
    "d_in = 10\n",
    "\n",
    "x = torch.rand((sl, bsz, d_in))\n",
    "\n",
    "x_a = x[0, :]  # first item\n",
    "\n",
    "A = torch.nn.Linear(d_in, m)\n",
    "\n",
    "u = A(x_a)\n",
    "print(u, u.size())\n",
    "z = u.repeat_interleave(n, 1)\n",
    "\n",
    "print(z)\n",
    "\n",
    "first_z_batch = z[1]\n",
    "print(first_z_batch.view(m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import rsm_k_winners\n",
    "reload(rsm_k_winners)\n",
    "\n",
    "def run_kwin(size=50, scatter=True):\n",
    "    return rsm_k_winners.KWinners.apply(torch.rand(size, size), 0, 10, 0, scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4548, 0.8208, 0.3500,  ..., 0.0000, 0.0000, 0.2274],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.8647, 0.0963,  ..., 0.7562, 0.0000, 0.6054],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3596, 0.8424, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4383, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.6986]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_kwin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scatter 0.9094837090015062\n",
      "no_scatter 10.072980703000212\n"
     ]
    }
   ],
   "source": [
    "from timeit import Timer\n",
    "\n",
    "t = Timer(lambda: run_kwin(scatter=True))\n",
    "print('scatter', t.timeit(number=10000))\n",
    "\n",
    "t = Timer(lambda: run_kwin(scatter=False))\n",
    "print('no_scatter', t.timeit(number=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1703, 0.4110, 0.3670],\n",
      "        [0.3609, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.4454]])\n",
      "tensor([[2, 1],\n",
      "        [2, 1],\n",
      "        [0, 1]])\n",
      "tensor([[0.0000, 0.4110, 0.3670],\n",
      "        [0.0000, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.0000]])\n",
      "tensor([[0.0000, 0.4110, 0.3670],\n",
      "        [0.0000, 0.5750, 0.4785],\n",
      "        [0.5245, 0.6524, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rsm_k_winners\n",
    "reload(rsm_k_winners)\n",
    "\n",
    "a = torch.rand(3, 3)\n",
    "\n",
    "print(a)\n",
    "\n",
    "res_scatter = rsm_k_winners.KWinners.apply(a.clone(), 0, 2, 0, True)\n",
    "res_no_scatter = rsm_k_winners.KWinners.apply(a.clone(), 0, 2, 0, False)\n",
    "\n",
    "print(res_scatter)\n",
    "print(res_no_scatter)\n",
    "bool(torch.all(torch.eq(res_scatter, res_no_scatter)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 8., 9., 7.],\n",
      "        [0., 9., 1., 8.],\n",
      "        [0., 4., 3., 6.],\n",
      "        [0., 5., 2., 3.],\n",
      "        [0., 1., 7., 5.],\n",
      "        [1., 0., 5., 4.],\n",
      "        [1., 6., 6., 9.],\n",
      "        [1., 7., 0., 0.],\n",
      "        [1., 3., 8., 1.],\n",
      "        [1., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_subsequences(start_digits=[0, 1], digits=10, length=4):\n",
    "    seq = torch.zeros(digits, length)\n",
    "    reps = int(np.ceil(digits / len(start_digits)))\n",
    "    first_col = torch.repeat_interleave(torch.tensor(start_digits), reps, 0)\n",
    "    seq[:, 0] = first_col[:digits]\n",
    "    for i in range(1, length):\n",
    "        column = torch.arange(digits)\n",
    "        idxs = torch.randperm(digits)\n",
    "        seq[:, i] = column[idxs]\n",
    "    print(seq)\n",
    "\n",
    "\n",
    "generate_subsequences(digits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 20, 784]) 3 torch.Size([8, 20, 32])\n",
      "tensor([[[ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         ...,\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028],\n",
      "         [ 0.1845, -0.1434,  0.0094,  ..., -0.1311,  0.5798, -0.4028]],\n",
      "\n",
      "        [[ 0.0951,  0.1785, -0.2497,  ..., -0.1264,  0.4125, -0.2198],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         ...,\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.2117,  0.0832, -0.1971,  ..., -0.2742,  0.4387, -0.5160],\n",
      "         [ 0.0951,  0.1785, -0.2497,  ..., -0.1264,  0.4125, -0.2198]],\n",
      "\n",
      "        [[-0.0182,  0.1280, -0.1884,  ..., -0.1021,  0.3155, -0.3728],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         ...,\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0188,  0.1279, -0.1883,  ..., -0.1022,  0.3147, -0.3722],\n",
      "         [-0.0182,  0.1280, -0.1884,  ..., -0.1021,  0.3155, -0.3728]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0954,  0.1780, -0.2471,  ..., -0.1273,  0.4118, -0.2232],\n",
      "         [ 0.0813,  0.1204, -0.2180,  ..., -0.0940,  0.3946, -0.2014],\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         ...,\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         [ 0.1862,  0.0503, -0.1621,  ..., -0.2358,  0.4162, -0.4851],\n",
      "         [ 0.1987,  0.1008, -0.1878,  ..., -0.2652,  0.4314, -0.5043]],\n",
      "\n",
      "        [[ 0.0270,  0.0948, -0.1481,  ..., -0.0955,  0.3490, -0.3901],\n",
      "         [ 0.0272,  0.0946, -0.1480,  ..., -0.0954,  0.3491, -0.3902],\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         ...,\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         [ 0.0265,  0.0952, -0.1487,  ..., -0.0955,  0.3487, -0.3900],\n",
      "         [ 0.0264,  0.0954, -0.1488,  ..., -0.0956,  0.3485, -0.3899]],\n",
      "\n",
      "        [[ 0.1856,  0.0515, -0.1618,  ..., -0.2356,  0.4160, -0.4847],\n",
      "         [ 0.2112,  0.0833, -0.1967,  ..., -0.2737,  0.4383, -0.5155],\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         ...,\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         [ 0.0953,  0.1778, -0.2472,  ..., -0.1272,  0.4118, -0.2229],\n",
      "         [ 0.0813,  0.1205, -0.2180,  ..., -0.0941,  0.3946, -0.2015]]],\n",
      "       grad_fn=<DifferentiableGraphBackward>) 1.2037055492401123\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(sl, bs, 28**2)\n",
    "\n",
    "x_b = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "phi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "psi = torch.zeros((bs, m*n), dtype=torch.float32, requires_grad=False)\n",
    "hidden = (x_b, phi, psi)\n",
    "\n",
    "del model \n",
    "model = torch.jit.load(\"/Users/jgordon/nta/results/rsm_jit.pt\")\n",
    "\n",
    "# print(model.graph)\n",
    "\n",
    "inputs, targets, pred_target, input_label = next(iter(loader))\n",
    "\n",
    "out, hidden, x_bs = model(inputs, hidden)\n",
    "print(out.size(), len(hidden), x_bs.size())\n",
    "total_loss = 0.0\n",
    "loss = criterion(out, targets)\n",
    "loss.backward()\n",
    "total_loss += loss.item()\n",
    "optimizer.step()\n",
    "print(out, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.values>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(5)\n",
    "\n",
    "torch.max(a.sum(), torch.Tensor(1)).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
