# ----------------------------------------------------------------------
# Numenta Platform for Intelligent Computing (NuPIC)
# Copyright (C) 2019, Numenta, Inc.  Unless you have an agreement
# with Numenta, Inc., for a separate license for this software code, the
# following terms and conditions apply:
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero Public License version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero Public License for more details.
#
# You should have received a copy of the GNU Affero Public License
# along with this program.  If not, see http://www.gnu.org/licenses.
#
# http://numenta.org/licenses/
# ----------------------------------------------------------------------

[DEFAULT]
# AWS sync
# Uncomment to upload results on S3
upload_dir = "s3://jgordon/ray/results"
sync_function = "aws s3 sync `dirname {local_dir}` {remote_dir}/`basename $(dirname {local_dir})`"

# Set to 'True' to save/restore the model on every iteration and repetition
restore_supported = True

experiment = grid
path = ~/nta/results
data_dir = ~/nta/datasets

# Data
input_size = (1, 28, 28)
output_size = 784
dataset = mnist
use_mnist_pct = 1.0

# Network parameters
m_groups = 200
n_cells_per_group = 6
k_winners = 25
k_winner_cells = 1
gamma = 0.5  # Inhibition
eps = 0.0  # Memory

sequences = [[0,1,2,3], [0,3,2,1]]
seq_length = 12
randomize_sequences = True
predictor_hidden_size=1200
predictor_output_size=4
decode_from_full_memory=False
pred_gain = 1.0

iterations = 200
repetitions = 1
batch_size = 300
embed_dim = 0  # No embedding
vocab_size = 0
learning_rate = 0.0005
learning_rate_gamma =  0 # 0.1
learning_rate_min = 0.000005
batches_in_epoch = 100
momentum = 0.9
lr_step_schedule = None # [20, 40, 60]
optimizer=adam
loss_function = MSELoss
save_onnx_graph_at_checkpoint = False

gpu_percentage = 1.0

stop = {"stop": 1}
checkpoint_at_end = False
eval_interval = 10
eval_batches_in_epoch = 120

#
# SMNIST4
#

################
[ORSM_SMNIST4]
iterations = 50
sequences = [[0,1,2,3], [0,3,2,1]]  # 87.5 pct
seq_length = 8
predictor_output_size=4
dropout_p = 0.5
gamma = 0.5
k_winner_cells=1
boost_strat = rsm_inhibition
x_b_norm = True

################
[Adj_SMNIST4]
iterations = 100
sequences = [[0,1,2,3], [0,3,2,1]]  # 87.5 pct
seq_length = 8
predictor_output_size=4
dropout_p = 0.0
gamma = 0.0
k_winner_cells=2
boost_strat = col_boosting
x_b_norm = False

################
[Flat_SMNIST4]
iterations = 60
sequences = [[0,1,2,3], [0,3,2,1]]  # 87.5 pct
seq_length = 8
predictor_output_size=4
dropout_p = 0.0
m_groups=1000
k_winners=25
n_cells_per_group=1
k_winner_cells=1
gamma = 0.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 3.0
mult_integration=True

#
# SMNIST6
#

################
[ORSM_SMNIST6]
iterations = 100
sequences=[[0, 3, 1, 0],[0, 4, 2, 1],[0, 2, 4, 5],[1, 0, 0, 2],[1, 5, 3, 4],[1, 1, 5, 3]]  # 70.82 pct
seq_length = 24
predictor_output_size=6
dropout_p = 0.5
gamma = 0.5
k_winner_cells=1
boost_strat = rsm_inhibition
x_b_norm = True

################
[Adj_SMNIST6]
iterations = 100
sequences=[[0, 3, 1, 0],[0, 4, 2, 1],[0, 2, 4, 5],[1, 0, 0, 2],[1, 5, 3, 4],[1, 1, 5, 3]]  # 70.82 pct
seq_length = 24
predictor_output_size=6
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
k_winner_cells=2
boost_strat = col_boosting
x_b_norm = False

################
[Flat_SMNIST6_K115]
iterations = 100
sequences=[[0, 3, 1, 0],[0, 4, 2, 1],[0, 2, 4, 5],[1, 0, 0, 2],[1, 5, 3, 4],[1, 1, 5, 3]]  # 70.82 pct
seq_length = 24
predictor_output_size=6
dropout_p = 0.0
m_groups=1000
k_winners=115
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 3.0
mult_integration=True

#
# SMNIST10
#


################
[ORSM_SMNIST10]
iterations = 50
sequences=[[0, 8, 9, 7], [0, 9, 1, 8],[0, 4, 3, 6],[0, 5, 2, 3],[0, 1, 7, 5],[1, 0, 5, 4],[1, 6, 6, 9],[1, 7, 0, 0],[1, 3, 8, 1],[1, 2, 4, 2]]  # 67.5 pct
seq_length = 40
predictor_output_size=10
dropout_p = 0.5
gamma = 0.5
k_winner_cells=1
boost_strat = rsm_inhibition
x_b_norm = True

################
[Adj_SMNIST10]
iterations = 100
sequences=[[0, 8, 9, 7], [0, 9, 1, 8],[0, 4, 3, 6],[0, 5, 2, 3],[0, 1, 7, 5],[1, 0, 5, 4],[1, 6, 6, 9],[1, 7, 0, 0],[1, 3, 8, 1],[1, 2, 4, 2]]  # 67.5 pct
seq_length = 40
predictor_output_size=10
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
k_winner_cells=2
boost_strat = col_boosting
x_b_norm = False

#
# PAGI9
#

################
[ORSM_PAGI9]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
seq_length = 72
predictor_output_size=10
dropout_p = 0.5
gamma = 0.5
k_winner_cells=1
boost_strat = rsm_inhibition
x_b_norm = True

################
[Adj_PAGI9]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
seq_length = 72
predictor_output_size=10
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
k_winner_cells=2
boost_strat = col_boosting
x_b_norm = False

################
[Flat_PAGI9]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
predictor_output_size=10
dropout_p = 0.0
m_groups=1000
k_winners=250
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 2.0
mult_integration=True

#
#
# Exploration
#
#

################
[Adj_PAGI9_M400N3]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
seq_length = 72
m_groups=400
n_cells_per_group=3
k_winners=50
predictor_output_size=10
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
k_winner_cells=1
boost_strat = col_boosting
x_b_norm = False

################
[Adj_PAGI9_M600_Mult]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
m_groups=600
k_winners=75
predictor_output_size=10
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
k_winner_cells=2
boost_strat = col_boosting
x_b_norm = False
mult_integration=True

################
[Flat_PAGI9_K250_Buf]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
predictor_output_size=10
dropout_p = 0.0
m_groups=1000
k_winners=250
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 2.0
mult_integration=True
noise_buffer=True

################
[Flat_PAGI9_K275_BoostPt5_bsf98]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
predictor_output_size=10
dropout_p = 0.0
m_groups=1000
k_winners=275
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 0.5
boost_strength_factor=0.98
mult_integration=True

################
[Flat_PAGI9_K275_BoostPt5_bsf98_Buf]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
predictor_output_size=10
dropout_p = 0.0
m_groups=1000
k_winners=275
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 0.5
boost_strength_factor=0.98
mult_integration=True
noise_buffer=True

################
[Flat_PAGI9_M500K80]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
predictor_output_size=10
dropout_p = 0.0
m_groups=500
k_winners=25
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 2.0
mult_integration=True

################
[Flat_PAGI9_M500K25_Buf]
iterations = 200
sequences=[[2, 4, 0, 7, 8, 1, 6, 1, 8],[2, 7, 4, 9, 5, 9, 3, 1, 0],[5, 7, 3, 4, 1, 3, 1, 6, 4],[1, 3, 7, 5, 2, 5, 5, 3, 4],[2, 9, 1, 9, 2, 8, 3, 2, 7],[1, 2, 6, 4, 8, 3, 5, 0, 3],[3, 8, 0, 5, 6, 4, 1, 3, 9],[4, 7, 5, 3, 7, 6, 7, 2, 4]]
noise_buffer=True
predictor_output_size=10
dropout_p = 0.0
m_groups=500
k_winners=25
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 2.0
mult_integration=True

################
[Adj_SMNIST6_CPC_PiNoNorm_PG4]
iterations = 50
sequences=[[0, 3, 1, 0],[0, 4, 2, 1],[0, 2, 4, 5],[1, 0, 0, 2],[1, 5, 3, 4],[1, 1, 5, 3]]  # 70.82 pct
predictor_output_size=6
dropout_p = 0.0
k_winner_cells=2
eps = 0.0
gamma = 0.0
pred_gain = 4.0
boost_strat = col_boosting
x_b_norm = False
predict_memory = 'cell' 
mask_shifted_pi = True  # RSM masks pre-shift sigma. Useful for mem-prediction


################
[Flat_SMNIST6_K65_Buf]
iterations = 60
sequences=[[0, 3, 1, 0],[0, 4, 2, 1],[0, 2, 4, 5],[1, 0, 0, 2],[1, 5, 3, 4],[1, 1, 5, 3]]  # 70.82 pct
noise_buffer=True
seq_length = 24
predictor_output_size=6
dropout_p = 0.0
m_groups=1000
k_winners=65
n_cells_per_group=1
k_winner_cells=1
eps = 0.0
gamma = 0.0
pred_gain = 1.0
boost_strat = col_boosting
x_b_norm = False
do_inhibition = False
boost_strength = 3.0
mult_integration=True


################
[Adj_SMNIST4_Tiny]
iterations = 30
m_groups = 40
k_winners=5
k_winner_cells=2
batch_size = 64
batches_in_epoch = 100
randomize_sequences = True
sequences = [[0,1,2,3], [0,3,2,1]]
seq_length = 8
predictor_output_size=4
predictor_hidden_size=1200
dropout_p = 0.0
eps = 0.0
gamma = 0.0
pred_gain = 1.0
decode_from_full_memory=False
boost_strat = col_boosting
x_b_norm = False
predict_memory = False

################
[LSTM_SMNIST4]
model_kind = lstm
learning_rate = 4.0
learning_rate_gamma = 0.25
iterations = 50
m_groups = 200
randomize_sequences = True
sequences = [[0,1,2,3], [0,3,2,1]]
seq_length = 8
predictor_output_size=4


