{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from torchnlp.datasets import penn_treebank_dataset\n",
    "import torch\n",
    "from torchnlp.samplers import BPTTBatchSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from rsm_samplers import MNISTSequenceSampler, ptb_pred_sequence_collate\n",
    "from ptb_lstm import LSTMModel\n",
    "import lang_util\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from importlib import reload \n",
    "from torch.utils.data import Sampler, BatchSampler\n",
    "import rsm\n",
    "from functools import reduce, partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
      "\n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \n",
      "\n",
      " mr. <unk> is chairman of <unk> n.v. the dutch publishing group \n",
      "\n",
      "init tensor([0, 0, 0,  ..., 0, 0, 0]) tensor(0)\n",
      "ids tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24])\n",
      "ids tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 27, 24])\n",
      "ids tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 27, 24, 39, 26, 40, 41, 42, 26, 43, 32, 44, 45, 46, 24])\n",
      "ids tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 27, 24, 39, 26, 40, 41, 42, 26, 43, 32, 44, 45, 46, 24, 47,\n",
      "        26, 27, 28, 29, 48, 49, 41, 42, 50, 51, 52, 53, 54, 55, 35, 36, 37, 42,\n",
      "        56, 57, 58, 59, 24])\n",
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former\n"
     ]
    }
   ],
   "source": [
    "reload(lang_util)\n",
    "corpus = lang_util.Corpus('/Users/jgordon/nta/datasets/PTB')\n",
    "\n",
    "print(corpus.read_out(corpus.train[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.LongTensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dictionary.idx2word[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import rsm_samplers\n",
    "import rsm\n",
    "import lang_util\n",
    "reload(rsm_samplers)\n",
    "reload(rsm)\n",
    "reload(lang_util)\n",
    "\n",
    "BS = 2\n",
    "VS = 10000\n",
    "EMB_DIM = 28\n",
    "m=200\n",
    "n=6\n",
    "\n",
    "MB = 3\n",
    "\n",
    "bwe = lang_util.BitwiseWordEmbedding()\n",
    "\n",
    "model = rsm.RSMLayer(m=m, n=n, d_in=EMB_DIM, d_out=EMB_DIM, embed_dim=EMB_DIM)\n",
    "collate_fn = partial(rsm_samplers.ptb_pred_sequence_collate, vector_dict=bwe.embedding_dict)\n",
    "\n",
    "sampler = rsm_samplers.PTBSequenceSampler(corpus.train, batch_size=BS, max_batches=MB)\n",
    "loader = DataLoader(corpus.train,\n",
    "                       batch_sampler=sampler,\n",
    "                       collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 can\n",
      "108 in\n",
      "32 the\n",
      "...\n",
      "8207 kitchen\n",
      "6762 walked\n",
      "35 a\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "x_b = torch.zeros((BS, m*n), dtype=torch.float32, requires_grad=False)\n",
    "phi = torch.zeros((BS, m*n), dtype=torch.float32, requires_grad=False)\n",
    "psi = torch.zeros((BS, m*n), dtype=torch.float32, requires_grad=False)\n",
    "hidden = (x_b, phi, psi)\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for batch_id, (inputs, target, pred_target, pred_input) in enumerate(loader):\n",
    "        word = pred_input[0].item()\n",
    "        print(word, corpus.read_out(word))\n",
    "        x_a, hidden = model(inputs, hidden)\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 39, 26, 40, 41, 42, 26, 43, 32, 44])\n",
      "nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[40:50])\n",
    "print(corpus.read_out(corpus.train[38:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# start = np.random.randint(10000)\n",
    "start = 0\n",
    "for word_id in corpus.train[start:start+60]:\n",
    "    print(word_id)\n",
    "    print(corpus.read_out(word_id.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitwiseWordEmbedding(object):\n",
    "\n",
    "    def __init__(self, vocab_size=10000, dim=28):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dict = {}\n",
    "        self.dim = dim\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        for i in range(self.vocab_size):\n",
    "            self.embedding_dict[i] = self.embed(i)\n",
    "\n",
    "    def embed(self, i):\n",
    "        first = \"{0:b}\".format(i).zfill(self.dim // 2)\n",
    "        return first + self.inverse(first)\n",
    "\n",
    "    def inverse(self, binstr):\n",
    "        return ''.join('1' if x == '0' else '0' for x in binstr)\n",
    "\n",
    "bwe = BitwiseWordEmbedding()\n",
    "\n",
    "bwe.embed(9381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23079028\n",
      "18930028\n"
     ]
    }
   ],
   "source": [
    "from util import count_parameters\n",
    "\n",
    "model = rsm.RSMLayer(m=600, n=8, d_in=EMB_DIM, d_out=EMB_DIM, embed_dim=EMB_DIM)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "model = rsm.RSMLayer(m=5000, n=1, d_in=EMB_DIM, d_out=EMB_DIM, embed_dim=EMB_DIM, fpartition=[0.25, 0, 0.75])\n",
    "\n",
    "print(count_parameters(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
